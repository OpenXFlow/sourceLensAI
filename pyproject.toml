[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "sourcelens"
version = "0.3.0"
description = "AI-powered tool to generate tutorials from source code or web content."
readme = "README.md"
authors = [
  { name = "Jozef Darida", email = "darijo2@yahoo.com" },
]
license = {text = "GPL-3.0-or-later"}
requires-python = ">=3.9"
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Topic :: Software Development :: Documentation",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
]
dependencies = [
    "PyYAML>=6.0",
    "attrs>=21.3.0",
    "typing-extensions>=4.0.0",
    "jsonschema>=4.0.1",
    "python-dotenv>=1.0.0",
    "requests>=2.28.0",
    "google-generativeai>=0.8.0",
    "google-cloud-aiplatform>=1.25.0",
]

[project.urls]
Homepage = "https://github.com/OpenXFlow/sourceLensAI"
Repository = "https://github.com/OpenXFlow/sourceLensAI"

[project.scripts]
sourcelens = "sourcelens.main:main"

[project.optional-dependencies]
code_analysis = [
    "GitPython>=3.1.0",
]
web_crawling = [
    "crawl4ai>=0.6.3",
    "yt-dlp>=2023.12.30",
    "webvtt-py>=0.5.1",
]
all = [
    "sourcelens[code_analysis]",
    "sourcelens[web_crawling]",
]
dev = [
    "pytest>=7.0",
    "ruff>=0.1.0",
    "mypy>=1.0",
    "pre-commit>=3.0",
    "build>=0.10.0",
    "types-PyYAML",
    "types-requests",
    "types-jsonschema",
]

[tool.setuptools]
# We don't need include-package-data = true when using package_data directly.

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
"FL01_code_analysis" = ["*.json"]
"FL02_web_crawling" = ["*.json"]


[tool.ruff]
line-length = 120
target-version = "py39"

[tool.ruff.lint]
select = [
    "E", "W", "F", "I", "C414", "B904", "BLE001",
    "D100", "D101", "D102", "D103", "D104", "D105", "D106", "D107",
    "D200", "D211", "D210", "D212",
    "D400", "D401", "D402", "D403", "D415",
    "ANN001", "ANN002", "ANN003", "ANN201", "ANN202", "ANN204", "ANN205", "ANN206",
    "UP006", "UP007",
    "TC001", "TC002",
    "C901", "PLR0912", "PLR0915", "PLW0603", "PLR2004", "PLE1206", "PLR0913",
    "RET504", "PTH", "FBT001", "FBT002", "PGH003", "SIM105", "F821", "F841", "RUF100"
]
ignore = [
    "D203", "D213", "ANN101", "ANN102", "ANN401", "S101",
]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
package_path = "src"
packages = ["sourcelens", "FL01_code_analysis", "FL02_web_crawling"]

# This section tells Mypy to ignore missing type information for these specific modules.
[[tool.mypy.overrides]]
module = [
    "yt_dlp.*",
    "crawl4ai.*",
    "webvtt.*"
]
ignore_missing_imports = true
