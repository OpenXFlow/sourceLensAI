# Crawl4AI Documentation Analysis

This document provides an overview of the `Crawl4AI` documentation analysis. The analysis was performed by crawling the content from the specified URL.

## Project Configuration

The following settings from `config.json` were used for the analysis of this project.

> **Note:** The configuration shown below is a simplified subset specific to this analysis run (e.g., for a command like `sourcelens --language English  web_crawling --crawl-url "https://docs.crawl4ai.com/core/cli/"   --processing-mode llm_extended" `). A complete `config.json` file for full application functionality must include all profiles (language and LLM) and configuration blocks for all supported flows.

```json
{
  "common": {
    "common_output_settings": {
      "default_output_name": "auto-generated",
      "main_output_directory": "output",
      "generated_text_language": "english"
    },
    "logging": {
      "log_dir": "logs",
      "log_level": "INFO"
    },
    "cache_settings": {
      "use_llm_cache": true,
      "llm_cache_file": ".cache/llm_cache.json"
    },
    "llm_default_options": {
      "max_retries": 5,
      "retry_wait_seconds": 20
    }
  },
  "FL02_web_crawling": {
    "enabled": true,
    "active_llm_provider_id": "gemini_flash_main",
    "crawler_options": {
      "processing_mode": "llm_extended",
      "max_depth_recursive": 2,
      "respect_robots_txt": true
    },
    "segmentation_options": {
      "enabled": true,
      "min_chunk_char_length": 150,
      "heading_levels_to_split_on": [1, 2, 3]
    },
    "output_options": {
      "include_content_inventory": true,
      "include_content_review": true
    }
  },
  "profiles": {
    "llm_profiles": [
      {
        "provider_id": "gemini_flash_main",
        "is_local_llm": false,
        "provider": "gemini",
        "model": "gemini-2.0-flash",
        "api_key_env_var": "GEMINI_API_KEY",
        "api_key": "Your_GEMINI_API_KEY"
      }
    ]
  }
}
```
---

*Generated by [SourceLens AI](https://github.com/openXFlow/sourceLensAI) using LLM: `gemini` (cloud) - model: `gemini-2.0-flash`*
