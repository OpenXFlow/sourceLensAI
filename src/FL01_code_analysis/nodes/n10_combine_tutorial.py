# Copyright (C) 2025 Jozef Darida (LinkedIn/Xing)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""Node responsible for combining generated tutorial components into final files."""

import logging
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Any, Final, Literal, Optional, cast

from typing_extensions import TypeAlias

from sourcelens.core import BaseNode, SLSharedContext
from sourcelens.core.common_types import (
    CodeAbstractionsList,
    CodeRelationshipsDict,
)
from sourcelens.utils._exceptions import LlmApiError
from sourcelens.utils.helpers import sanitize_filename

if TYPE_CHECKING:  # pragma: no cover
    pass

CombinePreparedInputs: TypeAlias = bool
CombineExecutionResult: TypeAlias = None
ChapterOrderListInternal: TypeAlias = list[int]
ChapterContentListInternal: TypeAlias = list[str]
IdentifiedScenarioListInternal: TypeAlias = list[str]
ChapterTypeLiteral: TypeAlias = Literal["standard", "diagrams", "source_index", "project_review"]
ChapterFileDataInternal: TypeAlias = dict[str, Any]
AllChaptersDataListInternal: TypeAlias = list[ChapterFileDataInternal]
DiagramMarkup: TypeAlias = Optional[str]
SequenceDiagramsList: TypeAlias = list[DiagramMarkup]
SharedDataForCombineInternal: TypeAlias = dict[str, Any]
ConfigDataInternal: TypeAlias = dict[str, Any]
LlmConfigDictInternal: TypeAlias = dict[str, Any]
SourceConfigDictInternal: TypeAlias = dict[str, Any]
OutputOptionsConfigDictInternal: TypeAlias = dict[str, Any]
DiagramConfigDictInternal: TypeAlias = dict[str, Any]

_FLOW_NAME_COMBINE_TUTORIAL: Final[str] = "FL01_code_analysis"
DIAGRAMS_CHAPTER_TITLE: Final[str] = "Architecture Diagrams"
DIAGRAMS_FILENAME_BASE: Final[str] = "diagrams"
SOURCE_INDEX_CHAPTER_TITLE: Final[str] = "Code Inventory"
SOURCE_INDEX_FILENAME_BASE: Final[str] = "code_inventory"
PROJECT_REVIEW_CHAPTER_TITLE: Final[str] = "Project Review"
PROJECT_REVIEW_FILENAME_BASE: Final[str] = "project_review"
INDEX_FILENAME: Final[str] = "index.md"
FOOTER_SEPARATOR: Final[str] = "\n\n---\n\n*Generated by"
PREV_LINK_REGEX: Final[re.Pattern[str]] = re.compile(
    r"^\s*(?:> ?)?Previously, we looked at\s+\[.*?\]\(.*?\)\.?\s*$",
    re.IGNORECASE | re.MULTILINE,
)
NEXT_LINK_REGEX: Final[re.Pattern[str]] = re.compile(
    r"^\s*(?:> ?)?Next, we will examine\s+\[.*?\]\(.*?\)\.?\s*$",
    re.IGNORECASE | re.MULTILINE,
)
H1_HEADING_REGEX: Final[re.Pattern[str]] = re.compile(r"^\s*#\s+.*$", re.MULTILINE)
DEFAULT_PROJECT_NAME_COMBINE: Final[str] = "sourcelens_tutorial_output"
DEFAULT_OUTPUT_DIR_COMBINE: Final[str] = "output"
FOOTER_PROVIDER_DEFAULT: Final[str] = "N/A"
FOOTER_MODEL_DEFAULT: Final[str] = "N/A"
FOOTER_SOURCE_LANG_DEFAULT: Final[str] = "N/A"
FILENAME_CHAPTER_PREFIX_WIDTH_COMBINE: Final[int] = 2
MAX_INT_FOR_SORTING: Final[int] = sys.maxsize
DEFAULT_DIAGRAM_FORMAT_NODE: Final[str] = "mermaid"

module_logger: logging.Logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class FooterInfo:
    """Encapsulate information needed to generate the file footer."""

    provider_name: str
    model_name: str
    is_local: bool
    source_language: str

    def format_footer(self) -> str:
        """Generate the formatted footer string.

        Returns:
            The formatted footer string.
        """
        location: str = "(local)" if self.is_local else "(cloud)"
        repo_link: str = "https://github.com/openXFlow/sourceLensAI"
        part1: str = f"{FOOTER_SEPARATOR} [SourceLens AI]({repo_link}) "
        part2: str = f"using LLM: `{self.provider_name}` {location} "
        part3: str = f"- model: `{self.model_name}` | Language Profile: `{self.source_language}`*"
        return part1 + part2 + part3


@dataclass(frozen=True)
class IndexContext:
    """Encapsulate context needed to prepare the index.md file content."""

    project_name: str
    relationships_data: CodeRelationshipsDict
    footer_info: FooterInfo
    repo_url: Optional[str] = None
    local_dir: Optional[str] = None
    relationship_flowchart_markup: DiagramMarkup = None
    chapter_files_data: AllChaptersDataListInternal = field(default_factory=list)
    diagram_config: "DiagramConfigDictInternal" = field(default_factory=dict)
    include_rel_flowchart: bool = field(init=False)

    def __post_init__(self) -> None:
        """Set derived diagram flags after initialization."""
        include_flag_val: Any = self.diagram_config.get("include_relationship_flowchart", False)
        include_flag: bool = include_flag_val if isinstance(include_flag_val, bool) else False
        object.__setattr__(self, "include_rel_flowchart", include_flag)


@dataclass
class DiagramMarkupContext:
    """Context for adding diagram markup to a content list."""

    content_parts: list[str]
    markup: DiagramMarkup
    diagram_title: str
    diagram_description: str
    diagram_format: str
    log_message: str


class CombineTutorial(BaseNode[CombinePreparedInputs, CombineExecutionResult]):
    """Combine generated tutorial components into final Markdown files.

    This node orchestrates the final assembly of all generated content. It:
    - Gathers standard chapters and enabled special chapters (diagrams, review, etc.).
    - Assigns final, sequential chapter numbers.
    - Updates H1 headings within chapter content to reflect the final numbers.
    - Injects "Next" and "Previous" navigation links.
    - Appends a standardized footer.
    - Generates a main `index.md` file with a table of contents.
    - Writes all final Markdown files to the output directory.
    """

    def _get_special_chapter_base_name(self, chapter_type: ChapterTypeLiteral) -> str:
        """Return the base filename for a special chapter type.

        Args:
            chapter_type: The type of the special chapter.

        Returns:
            The base filename string for that chapter type.
        """
        if chapter_type == "diagrams":
            return DIAGRAMS_FILENAME_BASE
        if chapter_type == "source_index":
            return SOURCE_INDEX_FILENAME_BASE
        if chapter_type == "project_review":
            return PROJECT_REVIEW_FILENAME_BASE
        self._log_warning("Unknown special chapter type '%s' for filename base generation.", chapter_type)
        return "special_chapter"

    def _add_diagram_markup(self, ctx: DiagramMarkupContext) -> bool:
        """Add a diagram's markup and description to a list of content parts.

        Args:
            ctx: A `DiagramMarkupContext` object containing the content list,
                 markup, and metadata for the diagram.

        Returns:
            True if the diagram markup was successfully added, False otherwise.
        """
        if ctx.markup and ctx.markup.strip():
            ctx.content_parts.append(f"## {ctx.diagram_title}\n")
            ctx.content_parts.append(f"{ctx.diagram_description}\n")
            ctx.content_parts.append(f"```{ctx.diagram_format}\n{ctx.markup.strip()}\n```\n")
            self._log_info(ctx.log_message)
            return True
        self._log_warning("Attempted to add diagram '%s', but markup was empty.", ctx.diagram_title)
        return False

    def _add_sequence_diagrams_markup(
        self,
        content_parts: list[str],
        seq_diag_markups: SequenceDiagramsList,
        identified_scenarios: IdentifiedScenarioListInternal,
        diagram_format: str,
    ) -> bool:
        """Add multiple sequence diagrams with descriptions to a content list.

        Args:
            content_parts: The list of strings to which diagram content will be appended.
            seq_diag_markups: A list of markup strings (or None) for sequence diagrams.
            identified_scenarios: A list of scenario descriptions corresponding to the markups.
            diagram_format: The diagram format string (e.g., "mermaid").

        Returns:
            True if at least one valid sequence diagram was added, False otherwise.
        """
        valid_markups_with_scenarios: list[tuple[str, str]] = []
        for i, markup_item in enumerate(seq_diag_markups):
            if markup_item and markup_item.strip():
                scenario_desc = f"Scenario {i + 1}"
                if i < len(identified_scenarios) and identified_scenarios[i] and identified_scenarios[i].strip():
                    scenario_desc = identified_scenarios[i]
                valid_markups_with_scenarios.append((scenario_desc, markup_item.strip()))
        if not valid_markups_with_scenarios:
            self._log_warning("No valid sequence diagram markups to add to diagrams chapter.")
            return False

        if not any("## Sequence Diagrams" in part for part in content_parts if part.startswith("## ")):
            content_parts.append("## Sequence Diagrams\n")
            desc_text = "These diagrams illustrate various interaction scenarios, "
            desc_text += "showcasing operations between components for specific use cases.\n"
            content_parts.append(desc_text)

        for scenario_desc, seq_markup in valid_markups_with_scenarios:
            content_parts.append(f"### {scenario_desc}\n")
            content_parts.append(f"```{diagram_format}\n{seq_markup}\n```\n")
        self._log_info("Adding %d Sequence Diagram(s) markup.", len(valid_markups_with_scenarios))
        return True

    def _add_prev_link(self, chapter_data: ChapterFileDataInternal, prev_link_text: Optional[str]) -> None:
        """Ensure the 'Previously...' navigation link exists once before H1 heading.

        Args:
            chapter_data: A dictionary representing the chapter, modified in-place.
            prev_link_text: The Markdown string for the "Previously..." link.
        """
        if not prev_link_text or not prev_link_text.strip():
            return
        content: str = str(chapter_data.get("content", "") or "")
        content, num_removed = PREV_LINK_REGEX.subn("", content)
        if num_removed > 0:
            self._log_info("Removed %d 'Previously...' link(s) from chapter.", num_removed)
        content = re.sub(r"^\s*\n", "", content, flags=re.MULTILINE).strip()
        h1_match = H1_HEADING_REGEX.search(content)
        if h1_match:
            start_index = h1_match.start()
            prefix_content = content[:start_index].rstrip()
            h1_and_rest = content[start_index:]
            new_parts = [
                prefix_content,
                f"\n\n{prev_link_text}\n\n" if prefix_content else f"{prev_link_text}\n\n",
                h1_and_rest,
            ]
            content = "".join(new_parts)
        else:
            content = f"{prev_link_text}\n\n{content}"
        chapter_data["content"] = content.strip()

    def _add_next_link(self, chapter_data: ChapterFileDataInternal, next_link_text: Optional[str]) -> None:
        """Ensure the 'Next...' navigation link exists once at the end of chapter content.

        Args:
            chapter_data: A dictionary representing the chapter, modified in-place.
            next_link_text: The Markdown string for the "Next..." link.
        """
        if not next_link_text or not next_link_text.strip():
            return
        content: str = str(chapter_data.get("content", "") or "")
        content, num_removed = NEXT_LINK_REGEX.subn("", content)
        if num_removed > 0:
            self._log_info("Removed %d 'Next...' link(s) from chapter.", num_removed)
        content = content.strip()
        content += f"\n\n{next_link_text}" if content else next_link_text
        chapter_data["content"] = content.strip()

    def _add_navigation_links_and_update_headings(
        self, all_chapters_data: AllChaptersDataListInternal, index_filename: str
    ) -> None:
        """Add navigation links and update H1 headings to match final chapter numbers.

        Args:
            all_chapters_data: A list of dictionaries, each representing a chapter's data.
            index_filename: The filename of the main index/overview page.
        """
        if not all_chapters_data:
            return
        for i, chapter_data in enumerate(all_chapters_data):
            new_chapter_num_str = chapter_data.get("num")
            chapter_name = chapter_data.get("name", "Untitled Chapter")
            content = str(chapter_data.get("content", ""))

            if isinstance(new_chapter_num_str, str) and new_chapter_num_str.isdigit():
                new_chapter_num = int(new_chapter_num_str)
                if new_chapter_num > 0:
                    new_heading = f"# Chapter {new_chapter_num}: {chapter_name}"
                    updated_content, _ = re.subn(H1_HEADING_REGEX, new_heading, content, count=1)
                    chapter_data["content"] = updated_content

            prev_link_text = None
            if i == 0:
                prev_link_text = f"> Previously, we looked at the [Project Overview]({index_filename})."
            elif i > 0:
                prev_ch_data = all_chapters_data[i - 1]
                p_name, p_file = str(prev_ch_data.get("name", "")), str(prev_ch_data.get("filename", ""))
                if p_name.strip() and p_file.strip():
                    prev_link_text = f"> Previously, we looked at [{p_name}]({p_file})."
            self._add_prev_link(chapter_data, prev_link_text)

            next_link_text = None
            if i < len(all_chapters_data) - 1:
                next_ch_data = all_chapters_data[i + 1]
                n_name, n_file = str(next_ch_data.get("name", "")), str(next_ch_data.get("filename", ""))
                if n_name.strip() and n_file.strip():
                    next_link_text = f"> Next, we will examine [{n_name}]({n_file})."
            self._add_next_link(chapter_data, next_link_text)

    def _add_footers(self, all_chapters_data: AllChaptersDataListInternal, footer_text: str) -> None:
        """Append the standard footer to all chapter contents, replacing existing ones.

        Args:
            all_chapters_data: A list of chapter data dictionaries. Modified in-place.
            footer_text: The footer text string to append.
        """
        if not footer_text.strip():
            return
        for chapter_data in all_chapters_data:
            current_content: str = str(chapter_data.get("content", "") or "")
            if FOOTER_SEPARATOR in current_content:
                current_content = current_content.split(FOOTER_SEPARATOR, 1)[0]
            current_content = current_content.rstrip()
            chapter_data["content"] = f"{current_content}\n{footer_text}" if current_content else footer_text.lstrip()

    def _prepare_index_header(self, context: IndexContext) -> list[str]:
        """Prepare the header section of the index.md file.

        Args:
            context: An `IndexContext` object containing project metadata.

        Returns:
            A list of Markdown strings for the header.
        """
        summary = str(context.relationships_data.get("overall_summary", f"Tutorial for {context.project_name}."))
        header_parts: list[str] = [f"# Tutorial: {context.project_name}\n\n{summary}\n"]
        source_info: str = ""
        if context.repo_url:
            source_info = f"**Source Repository:** [{context.repo_url}]({context.repo_url})"
        elif context.local_dir:
            source_info = f"**Source Directory:** `{str(Path(context.local_dir).resolve(strict=False))}`"
        if source_info:
            header_parts.append(f"{source_info}\n")
        return header_parts

    def _prepare_index_diagram(self, context: IndexContext) -> list[str]:
        """Prepare the relationship diagram section for the index.md file.

        Args:
            context: An `IndexContext` object containing diagram configurations and markup.

        Returns:
            A list of Markdown strings for the diagram section.
        """
        diagram_parts: list[str] = []
        fmt = str(context.diagram_config.get("format", DEFAULT_DIAGRAM_FORMAT_NODE))
        if context.include_rel_flowchart and context.relationship_flowchart_markup:
            markup = str(context.relationship_flowchart_markup).strip()
            if markup:
                diagram_parts.extend(["## Abstraction Relationships\n", f"```{fmt}\n{markup}\n```\n"])
                self._log_info("Embedding relationship flowchart into index.md.")
        return diagram_parts

    def _get_sort_number(self, value: Any) -> int:
        """Safely convert a value to an integer for sorting.

        Args:
            value: The value to convert, which can be int, float, str, or None.

        Returns:
            The converted integer, or a large fallback value.
        """
        if isinstance(value, str) and value.isdigit():
            return int(value)
        if isinstance(value, int):
            return value
        if isinstance(value, float):
            return int(value)
        return MAX_INT_FOR_SORTING

    def _get_chapter_sort_key(self, ch_data: ChapterFileDataInternal) -> tuple[int, int, str]:
        """Provide a sort key for chapters to ensure correct ordering in index.md.

        Args:
            ch_data: A dictionary representing a chapter's metadata.

        Returns:
            A tuple used for sorting: (primary_group, secondary_key, name).
        """
        ch_type = cast(ChapterTypeLiteral, ch_data.get("chapter_type", "standard"))
        final_num = self._get_sort_number(ch_data.get("num"))
        primary_sort_group: int
        secondary_sort_key: int
        if ch_type == "standard":
            primary_sort_group, secondary_sort_key = 0, final_num
        else:
            primary_sort_group = 1
            special_order_map: dict[ChapterTypeLiteral, int] = {"diagrams": 1, "source_index": 2, "project_review": 3}
            secondary_sort_key = special_order_map.get(ch_type, 99)
        return primary_sort_group, secondary_sort_key, str(ch_data.get("name", ""))

    def _prepare_index_chapters(self, context: IndexContext) -> list[str]:
        """Prepare the chapters listing section of the index.md file.

        Args:
            context: An `IndexContext` object containing the list of all chapter data.

        Returns:
            A list of Markdown strings for the chapter list.
        """
        chapter_parts: list[str] = ["## Chapters\n"]
        try:
            sorted_chapters = sorted(context.chapter_files_data, key=self._get_chapter_sort_key)
        except (TypeError, ValueError) as e_sort:
            self._log_warning("Cannot sort chapters for index.md; using provided order. Error: %s", e_sort)
            sorted_chapters = context.chapter_files_data
        chapter_links: list[str] = []
        for ch in sorted_chapters:
            num_str = ch.get("num")
            name_str = str(ch.get("name", "")).strip()
            filename_str = str(ch.get("filename", "")).strip()
            if isinstance(num_str, str) and num_str.isdigit() and int(num_str) > 0 and name_str and filename_str:
                chapter_links.append(f"{num_str}. [{name_str}]({filename_str})")
        chapter_parts.append("\n".join(chapter_links) if chapter_links else "No chapters available.")
        return chapter_parts

    def _prepare_index_content(self, context: IndexContext) -> str:
        """Prepare the full Markdown content for the index.md file.

        Args:
            context: An `IndexContext` containing all necessary data.

        Returns:
            A string of the complete index.md content.
        """
        self._log_info("Preparing index.md content for project '%s'...", context.project_name)
        content_parts: list[str] = self._prepare_index_header(context)
        content_parts.extend(self._prepare_index_diagram(context))
        content_parts.extend(self._prepare_index_chapters(context))
        return "\n".join(content_parts)

    def _prepare_standard_chapters_data(
        self,
        abstractions: CodeAbstractionsList,
        chapter_order: ChapterOrderListInternal,
        chapters_content: ChapterContentListInternal,
    ) -> AllChaptersDataListInternal:
        """Prepare initial data structure for standard chapter files from abstractions.

        Args:
            abstractions: The list of all identified abstractions for the project.
            chapter_order: A list of integer indices specifying the pedagogical order.
            chapters_content: A list of Markdown strings, one for each chapter.

        Returns:
            A list of dictionaries, each representing a standard chapter.
        """
        std_chapters_data: AllChaptersDataListInternal = []
        num_abstractions = len(abstractions)
        effective_count = min(len(chapter_order), len(chapters_content))
        if len(chapter_order) != len(chapters_content):
            self._log_warning(
                "Chapter order count (%d) != content count (%d). Processing %d items.",
                len(chapter_order),
                len(chapters_content),
                effective_count,
            )
        for i in range(effective_count):
            abstraction_idx = chapter_order[i]
            if not (0 <= abstraction_idx < num_abstractions):
                continue
            name = str(abstractions[abstraction_idx].get("name", f"Concept {i + 1}")).strip()
            content = str(chapters_content[i] or "").strip()
            if not (name and content):
                continue
            std_chapters_data.append(
                {
                    "content": content,
                    "name": name,
                    "abstraction_index": abstraction_idx,
                    "chapter_type": "standard",
                    "filename": "",
                    "num": "-1",
                }
            )
        self._log_info("Prepared data for %d standard chapters.", len(std_chapters_data))
        return std_chapters_data

    def _prepare_special_chapter_data(
        self,
        content_key: str,
        title: str,
        chapter_type: ChapterTypeLiteral,
        shared_context: SLSharedContext,
    ) -> Optional[ChapterFileDataInternal]:
        """Prepare data structure for a special chapter (e.g., diagrams, review).

        Args:
            content_key: The key in `shared_context` where the chapter's content is stored.
            title: The title for this special chapter.
            chapter_type: The literal type of the special chapter.
            shared_context: The shared context dictionary.

        Returns:
            A dictionary representing the special chapter, or None if no content is found.
        """
        content_val: Any = shared_context.get(content_key)
        if not (content_val and isinstance(content_val, str) and content_val.strip()):
            return None
        return {
            "filename": "",
            "content": content_val,
            "name": title,
            "num": "-1",
            "abstraction_index": -1,
            "chapter_type": chapter_type,
        }

    def _add_and_assign_numbers_to_special_chapters(
        self,
        all_chapters_list: AllChaptersDataListInternal,
        shared_context: SLSharedContext,
        output_opts: OutputOptionsConfigDictInternal,
        diagram_cfg: DiagramConfigDictInternal,
        starting_chapter_number: int,
    ) -> None:
        """Add enabled special chapters to the list and assign them temporary sort numbers.

        Args:
            all_chapters_list: The list of chapter data to be appended to.
            shared_context: The main shared context dictionary.
            output_opts: Configuration for output options.
            diagram_cfg: Configuration for diagram generation.
            starting_chapter_number: The number to start assigning from.
        """
        current_num = starting_chapter_number
        if bool(diagram_cfg.get("enabled", False)):
            diagram_content = self._create_diagrams_chapter_content(shared_context, diagram_cfg)
            if diagram_content:
                diag_ch = {"content": diagram_content, "name": DIAGRAMS_CHAPTER_TITLE, "chapter_type": "diagrams"}
                diag_ch["num"] = str(current_num)
                all_chapters_list.append(diag_ch)
                current_num += 1
        if bool(output_opts.get("include_source_index", False)):
            inv_ch = self._prepare_special_chapter_data(
                "source_index_content", SOURCE_INDEX_CHAPTER_TITLE, "source_index", shared_context
            )
            if inv_ch:
                inv_ch["num"] = str(current_num)
                all_chapters_list.append(inv_ch)
                current_num += 1
        if bool(output_opts.get("include_project_review", False)):
            rev_ch = self._prepare_special_chapter_data(
                "project_review_content", PROJECT_REVIEW_CHAPTER_TITLE, "project_review", shared_context
            )
            if rev_ch:
                rev_ch["num"] = str(current_num)
                all_chapters_list.append(rev_ch)

    def _assemble_chapters(
        self, shared_context: SLSharedContext, data_for_combine: SharedDataForCombineInternal
    ) -> AllChaptersDataListInternal:
        """Assemble all chapter data, sort, and assign final numbers/filenames.

        Args:
            shared_context: The main shared context dictionary.
            data_for_combine: A dictionary of required data for this process.

        Returns:
            A list of chapter data dictionaries, sorted and fully numbered.
        """
        self._log_info("Assembling all chapter data for code analysis output...")
        flow_settings: dict[str, Any] = data_for_combine["config"].get(_FLOW_NAME_COMBINE_TUTORIAL, {})
        output_opts: OutputOptionsConfigDictInternal = flow_settings.get("output_options", {})
        diagram_cfg: DiagramConfigDictInternal = flow_settings.get("diagram_generation", {})
        all_chapters = self._prepare_standard_chapters_data(
            data_for_combine["abstractions"],
            data_for_combine["chapter_order"],
            data_for_combine["chapters_content"],
        )
        self._add_and_assign_numbers_to_special_chapters(
            all_chapters, shared_context, output_opts, diagram_cfg, len(all_chapters) + 1
        )
        all_chapters.sort(key=self._get_chapter_sort_key)

        for i, chapter_info in enumerate(all_chapters):
            chapter_info["num"] = str(i + 1)
            name_raw = str(chapter_info.get("name", f"chapter-{i + 1}"))
            ch_type = cast(ChapterTypeLiteral, chapter_info.get("chapter_type", "standard"))
            base_name_parts: list[str] = [
                self._get_special_chapter_base_name(ch_type)
                if ch_type in ["diagrams", "source_index", "project_review"]
                else (sanitize_filename(name_raw) or f"chapter-{i + 1}")
            ]
            base_name = "-".join(filter(None, base_name_parts))
            chapter_info["filename"] = f"{i + 1:0{FILENAME_CHAPTER_PREFIX_WIDTH_COMBINE}d}_{base_name}.md"
        self._log_info("Assembled and numbered %d chapters for final output.", len(all_chapters))
        return all_chapters

    def _create_diagrams_chapter_content(
        self, shared_context: SLSharedContext, diagram_config: DiagramConfigDictInternal
    ) -> Optional[str]:
        """Create the Markdown content for the "Architecture Diagrams" special chapter.

        Args:
            shared_context: The shared context containing all generated diagram markups.
            diagram_config: The configuration dictionary for diagram generation.

        Returns:
            A string with the combined Markdown content, or None if no diagrams were generated.
        """
        content_parts: list[str] = [f"# {DIAGRAMS_CHAPTER_TITLE}\n"]
        fmt = str(diagram_config.get("format", DEFAULT_DIAGRAM_FORMAT_NODE))
        proj = str(shared_context.get("project_name", DEFAULT_PROJECT_NAME_COMBINE))
        has_any_diagram_content = False
        if bool(diagram_config.get("include_class_diagram", False)):
            ctx = DiagramMarkupContext(
                content_parts,
                shared_context.get("class_diagram_markup"),
                "Class Diagram",
                f"Key classes and their relationships in **{proj}**.",
                fmt,
                "Adding Class Diagram to diagrams chapter.",
            )
            if self._add_diagram_markup(ctx):
                has_any_diagram_content = True
        if bool(diagram_config.get("include_package_diagram", False)):
            ctx_pkg = DiagramMarkupContext(
                content_parts,
                shared_context.get("package_diagram_markup"),
                "Package Dependencies",
                f"High-level module and package structure of **{proj}**.",
                fmt,
                "Adding Package Diagram to diagrams chapter.",
            )
            if self._add_diagram_markup(ctx_pkg):
                has_any_diagram_content = True
        seq_cfg: DiagramConfigDictInternal = diagram_config.get("sequence_diagrams", {})
        if bool(seq_cfg.get("enabled", False)):
            markups: SequenceDiagramsList = shared_context.get("sequence_diagrams_markup", [])
            scenarios: IdentifiedScenarioListInternal = shared_context.get("identified_scenarios", [])
            if self._add_sequence_diagrams_markup(content_parts, markups, scenarios, fmt):
                has_any_diagram_content = True
        return "\n".join(content_parts) if has_any_diagram_content else None

    def _process_and_write_tutorial_files(
        self,
        shared_context: SLSharedContext,
        data_for_combine: SharedDataForCombineInternal,
        footer_info: FooterInfo,
        output_path_obj: Path,
    ) -> bool:
        """Orchestrate chapter assembly, formatting, and writing all tutorial files.

        Args:
            shared_context: The main shared context dictionary.
            data_for_combine: Required data for combining.
            footer_info: Information for the file footer.
            output_path_obj: The `Path` object for the main output directory.

        Returns:
            True if all files were written successfully, False otherwise.
        """
        all_chapters = self._assemble_chapters(shared_context, data_for_combine)
        rel_flow_markup = cast(DiagramMarkup, data_for_combine.get("relationship_flowchart_markup"))
        if not all_chapters and not (rel_flow_markup and rel_flow_markup.strip()):
            shared_context["final_output_dir"] = str(output_path_obj.resolve())
            return True

        flow_settings: dict[str, Any] = data_for_combine["config"].get(_FLOW_NAME_COMBINE_TUTORIAL, {})
        diag_cfg: DiagramConfigDictInternal = flow_settings.get("diagram_generation", {})
        idx_ctx = IndexContext(
            project_name=str(data_for_combine.get("project_name")),
            relationships_data=cast(CodeRelationshipsDict, data_for_combine["relationships_data"]),
            footer_info=footer_info,
            repo_url=cast(Optional[str], data_for_combine.get("repo_url")),
            local_dir=cast(Optional[str], data_for_combine.get("local_dir")),
            relationship_flowchart_markup=rel_flow_markup,
            chapter_files_data=all_chapters,
            diagram_config=diag_cfg,
        )
        index_md_content = self._prepare_index_content(idx_ctx)
        footer_str = footer_info.format_footer()
        if FOOTER_SEPARATOR not in index_md_content:
            index_md_content = index_md_content.rstrip() + f"\n{footer_str}"

        self._add_navigation_links_and_update_headings(all_chapters, INDEX_FILENAME)
        self._add_footers(all_chapters, footer_str)
        return self._write_output_files(output_path_obj, index_md_content, all_chapters)

    def _write_output_files(
        self, output_path: Path, index_content: str, all_chapter_files_data: AllChaptersDataListInternal
    ) -> bool:
        """Write the index.md and all generated chapter files to disk.

        Args:
            output_path: The `Path` object for the directory where files will be written.
            index_content: The full Markdown content for the `index.md` file.
            all_chapter_files_data: A list of dictionaries, each with chapter 'filename' and 'content'.

        Returns:
            True if all write operations succeed, False otherwise.

        Raises:
            LlmApiError: Re-raises OSError as LlmApiError for consistent flow handling.
        """
        try:
            output_path.mkdir(parents=True, exist_ok=True)
        except OSError as e_dir:
            raise LlmApiError(f"Failed to create output directory {output_path}: {e_dir}") from e_dir
        try:
            (output_path / INDEX_FILENAME).write_text(index_content, encoding="utf-8")
        except OSError as e_idx:
            self._log_error("CRITICAL: Failed to write index file %s: %s", (output_path / INDEX_FILENAME), e_idx)
            return False

        all_writes_ok = True
        for ch_info in all_chapter_files_data:
            fname, content = str(ch_info.get("filename", "")), str(ch_info.get("content", ""))
            if not (fname.strip() and content.strip()):
                continue
            try:
                (output_path / fname).write_text(content, encoding="utf-8")
            except OSError as e_ch:
                self._log_error("Failed to write chapter file %s: %s", (output_path / fname), e_ch)
                all_writes_ok = False
        return all_writes_ok

    def _retrieve_shared_data(self, shared_context: SLSharedContext) -> SharedDataForCombineInternal:
        """Retrieve all necessary data from shared context for combination logic.

        Args:
            shared_context: The main shared context dictionary.

        Returns:
            A dictionary containing all required data.

        Raises:
            ValueError: If a required key is missing from the shared context.
        """
        return {
            "project_name": self._get_required_shared(shared_context, "project_name"),
            "output_dir": self._get_required_shared(shared_context, "output_dir"),
            "relationships_data": self._get_required_shared(shared_context, "relationships"),
            "chapter_order": self._get_required_shared(shared_context, "chapter_order"),
            "abstractions": self._get_required_shared(shared_context, "abstractions"),
            "chapters_content": self._get_required_shared(shared_context, "chapters"),
            "llm_config": self._get_required_shared(shared_context, "llm_config"),
            "source_config": self._get_required_shared(shared_context, "source_config"),
            "config": self._get_required_shared(shared_context, "config"),
            "repo_url": shared_context.get("repo_url"),
            "local_dir": shared_context.get("local_dir"),
            "relationship_flowchart_markup": shared_context.get("relationship_flowchart_markup"),
        }

    def _initialize_combine_data(
        self, shared_context: SLSharedContext
    ) -> tuple[SharedDataForCombineInternal, FooterInfo, Path]:
        """Initialize data structures needed for combining the tutorial.

        Args:
            shared_context: The main shared context dictionary.

        Returns:
            A tuple containing the retrieved shared data, footer information, and resolved output path.
        """
        retrieved_data = self._retrieve_shared_data(shared_context)
        llm_cfg = cast(LlmConfigDictInternal, retrieved_data.get("llm_config", {}))
        src_cfg = cast(SourceConfigDictInternal, retrieved_data.get("source_config", {}))
        footer_info = FooterInfo(
            provider_name=str(llm_cfg.get("provider", FOOTER_PROVIDER_DEFAULT)),
            model_name=str(llm_cfg.get("model", FOOTER_MODEL_DEFAULT)),
            is_local=bool(llm_cfg.get("is_local_llm", False)),
            source_language=str(src_cfg.get("language_name_for_llm", FOOTER_SOURCE_LANG_DEFAULT)),
        )
        project_name_str = str(retrieved_data.get("project_name", DEFAULT_PROJECT_NAME_COMBINE))
        output_base_dir_str = str(retrieved_data.get("output_dir", DEFAULT_OUTPUT_DIR_COMBINE))
        output_path_obj = Path(output_base_dir_str) / project_name_str
        return retrieved_data, footer_info, output_path_obj.resolve()

    def pre_execution(self, shared_context: SLSharedContext) -> CombinePreparedInputs:
        """Prepare all tutorial content and trigger writing of output files.

        This method orchestrates the entire assembly and file writing process.
        It is the main entry point for this node's logic.

        Args:
            shared_context: The main shared context dictionary.

        Returns:
            True if the writing process was successful, False otherwise.
        """
        self._log_info("Starting final assembly and writing of tutorial files.")
        write_success = False
        try:
            retrieved_data, footer_obj, output_path = self._initialize_combine_data(shared_context)
            write_success = self._process_and_write_tutorial_files(
                shared_context, retrieved_data, footer_obj, output_path
            )
            shared_context["final_output_dir"] = str(output_path) if write_success else None
        except (ValueError, OSError, LlmApiError) as e_crit:
            self._log_error("Critical error during file combination: %s", e_crit, exc_info=True)
            write_success = False
        self._log_info("Finished file combination. Success: %s", write_success)
        return write_success

    def execution(self, prepared_inputs: CombinePreparedInputs) -> CombineExecutionResult:
        """Execute step for CombineTutorial (no-op).

        The core work is done in `pre_execution` to ensure file writing
        happens once and is not subject to retries.

        Args:
            prepared_inputs: The boolean result from `pre_execution`.

        Returns:
            None.
        """
        self._log_info("Execution phase is a no-op. Pre-execution success: %s.", prepared_inputs)
        return None

    def post_execution(
        self,
        shared_context: SLSharedContext,
        prepared_inputs: CombinePreparedInputs,
        execution_outputs: CombineExecutionResult,
    ) -> None:
        """Finalize the node's operation, logging the outcome.

        Args:
            shared_context: The shared context dictionary.
            prepared_inputs: The boolean result from `pre_execution`.
            execution_outputs: The result from `execution` (always None).
        """
        del prepared_inputs, execution_outputs
        final_dir = shared_context.get("final_output_dir")
        final_dir_str = str(final_dir) if final_dir and isinstance(final_dir, str) else "Not set"
        status = "successfully" if final_dir and Path(final_dir_str).exists() else "with potential issues"
        self._log_info("Post-execution finished %s. Final output dir: %s", status, final_dir_str)


# End of src/FL01_code_analysis/nodes/n10_combine_tutorial.py
