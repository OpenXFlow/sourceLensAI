# src/sourcelens/nodes/combine.py

"""Node responsible for combining generated tutorial components into final files."""

import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional, TypeAlias

from sourcelens.nodes.base_node import BaseNode, SharedState
from sourcelens.utils.helpers import sanitize_filename

# --- Type Aliases ---
AbstractionsList: TypeAlias = list[dict[str, Any]]
RelationshipsDict: TypeAlias = dict[str, Any]
ChapterOrderList: TypeAlias = list[int]
ChapterContentList: TypeAlias = list[str]
ChapterFileData: TypeAlias = dict[str, Any]  # Represents data for one chapter file
DiagramMarkup: TypeAlias = str
SequenceDiagramsList: TypeAlias = list[DiagramMarkup]
DiagramConfigDict: TypeAlias = dict[str, Any]
SequenceDiagramConfigDict: TypeAlias = dict[str, Any]
IdentifiedScenarioList: TypeAlias = list[str]  # From IdentifyScenariosNode

CombinePrepResult: TypeAlias = bool
CombineExecResult: TypeAlias = None

logger = logging.getLogger(__name__)

# --- Constants ---
DIAGRAMS_CHAPTER_TITLE = "Architecture Diagrams"
DIAGRAMS_FILENAME_BASE = "diagrams"


# --- Dataclasses ---
@dataclass(frozen=True)
class FooterInfo:
    """Encapsulates information needed to generate the file footer.

    Attributes:
        provider_name: Name of the LLM provider used.
        model_name: Name of the LLM model used.
        is_local: Flag indicating if the LLM is local.
        source_language: The language profile used for analysis.

    """

    provider_name: str
    model_name: str
    is_local: bool
    source_language: str

    def format_footer(self) -> str:
        """Generate the formatted footer string including all details.

        Returns:
            A formatted Markdown string for the file footer.

        """
        location = "(local)" if self.is_local else "(cloud)"
        repo_link = "https://github.com/darijo2yahoocom/sourceLensAI"
        return (
            f"\n\n---\n\n*Generated by [SourceLens AI]({repo_link}) "
            f"using LLM: `{self.provider_name}` {location} - model: `{self.model_name}` | "
            f"Language Profile: `{self.source_language}`*"
        )


@dataclass(frozen=True)
class IndexContext:
    """Encapsulates context needed to prepare the index.md file content.

    Attributes:
        project_name: The name of the project.
        relationships_data: Dictionary containing relationship summary and details.
        footer_info: FooterInfo dataclass instance.
        repo_url: The URL of the source GitHub repository, if applicable.
        local_dir: The path to the source local directory, if applicable.
        relationship_flowchart_markup: Mermaid markup for the relationship flowchart.
        chapter_files_data: List of dictionaries representing all chapter files (including diagrams).
        diagram_config: The 'diagram_generation' section from the configuration.
        include_rel_flowchart: Flag to include the relationship flowchart.

    """

    # Arguments without defaults first
    project_name: str
    relationships_data: RelationshipsDict
    footer_info: FooterInfo

    # Arguments with defaults or Optional that can be None
    repo_url: Optional[str] = None
    local_dir: Optional[str] = None
    relationship_flowchart_markup: Optional[DiagramMarkup] = None
    chapter_files_data: list[ChapterFileData] = field(default_factory=list)
    diagram_config: DiagramConfigDict = field(default_factory=dict)

    # Derived fields
    include_rel_flowchart: bool = field(init=False)

    def __post_init__(self) -> None:
        """Set derived diagram flags after initialization."""
        object.__setattr__(
            self, "include_rel_flowchart", self.diagram_config.get("include_relationship_flowchart", False)
        )


class CombineTutorial(BaseNode):
    """Combine generated tutorial parts into final Markdown files.

    Assembles index.md (with only relationship flowchart), standard chapter files,
    and a dedicated diagrams chapter (containing class, package, sequence diagrams).
    Adds attributions and writes the complete tutorial structure.
    """

    def _prepare_index_content(self, context: IndexContext) -> str:
        """Prepare the full Markdown content for the index.md file.

        Includes project summary, source info, relationship flowchart (if enabled),
        and the list of chapter links (including the diagrams chapter link).

        Args:
            context: An IndexContext object containing necessary data.

        Returns:
            A string containing the complete Markdown content for index.md.

        """
        self._log_info("Preparing index.md content...")
        summary_raw = context.relationships_data.get("summary", f"Tutorial for {context.project_name}.")
        summary = str(summary_raw or f"Tutorial for {context.project_name}.")
        index_content_parts: list[str] = [f"# Tutorial: {context.project_name}\n\n{summary}\n"]

        source_info = ""
        if context.repo_url:
            source_info = f"**Source Repository:** [{context.repo_url}]({context.repo_url})"
        elif context.local_dir:
            try:
                resolved_path = Path(context.local_dir).resolve(strict=True)
                source_info = f"**Source Directory:** `{resolved_path}`"
            except (OSError, ValueError) as e:
                logger.warning(
                    "Cannot resolve local directory path '%s': %s. Using original path.", context.local_dir, e
                )
                source_info = f"**Source Directory:** `{context.local_dir}`"
        if source_info:
            index_content_parts.append(f"{source_info}\n")

        diagram_format = context.diagram_config.get("format", "mermaid")

        # --- Embed ONLY Relationship Flowchart ---
        if context.include_rel_flowchart:
            if context.relationship_flowchart_markup:
                index_content_parts.extend(
                    [
                        "## Abstraction Relationships\n",
                        f"```{diagram_format}\n{context.relationship_flowchart_markup}\n```\n",
                    ]
                )
                self._log_info("Embedding relationship flowchart into index.md.")
            else:
                self._log_warning("Relationship flowchart enabled but no markup found for index.md.")
        # --- Class, Package, Sequence diagrams are NOT embedded here ---

        # Chapters List (includes link to the diagrams chapter if generated)
        index_content_parts.append("## Chapters\n")
        try:
            sorted_chapters = sorted(context.chapter_files_data, key=lambda x: x.get("num", float("inf")))
        except TypeError:
            logger.warning("Cannot sort chapters based on 'num' key. Using original order.")
            sorted_chapters = context.chapter_files_data

        chapter_links: list[str] = []
        for ch_data in sorted_chapters:
            num = ch_data.get("num")
            name = ch_data.get("name")
            fname = ch_data.get("filename")
            if isinstance(num, int) and isinstance(name, str) and isinstance(fname, str):
                chapter_links.append(f"{num}. [{name}]({fname})")
            else:
                logger.warning("Skipping chapter link due to invalid data format: %s", ch_data)

        index_content_parts.append("\n".join(chapter_links))
        index_content_parts.append(context.footer_info.format_footer())  # Add footer
        self._log_info("Prepared index.md content string.")
        return "\n".join(index_content_parts)

    def _prepare_standard_chapters_data(
        self,
        abstractions: AbstractionsList,
        chapter_order: ChapterOrderList,
        chapters_content: ChapterContentList,
        footer_info: FooterInfo,
    ) -> list[ChapterFileData]:
        """Prepare data structure for each standard chapter file, adding dynamic footer.

        Args:
            abstractions: List of identified abstraction dictionaries.
            chapter_order: Ordered list of abstraction indices representing chapter sequence.
            chapters_content: List of generated Markdown content strings for each chapter.
            footer_info: Dataclass containing LLM and source language details for the footer.

        Returns:
            A list of dictionaries for standard chapters (filename, content, name, index, number).

        """
        standard_chapters_data: list[ChapterFileData] = []
        num_abstractions = len(abstractions)
        num_content_items = len(chapters_content)
        num_order_items = len(chapter_order)

        effective_chapter_count = min(num_order_items, num_content_items)
        if num_order_items != num_content_items:
            logger.warning(
                "Mismatch between chapter order length (%d) and chapter content count (%d). Processing %d chapters.",
                num_order_items,
                num_content_items,
                effective_chapter_count,
            )

        footer = footer_info.format_footer()
        for i in range(effective_chapter_count):
            abs_idx = chapter_order[i]
            if not (0 <= abs_idx < num_abstractions):
                logger.warning("Skipping chapter preparation: Invalid abstraction index %d.", abs_idx)
                continue

            try:
                abs_name_raw = abstractions[abs_idx].get("name", f"Chapter {i + 1}")
                abs_name = str(abs_name_raw or f"Chapter {i + 1}")
            except IndexError:
                logger.error("Index error accessing abstraction name at index %d. Using default.", abs_idx)
                abs_name = f"Chapter {i + 1}"

            safe_name = sanitize_filename(abs_name)
            filename = f"{i + 1:02d}_{safe_name}.md"
            ch_content_raw = chapters_content[i]
            ch_content = str(ch_content_raw or "")

            if not ch_content.rstrip().endswith(footer.strip()):
                ch_content += footer

            standard_chapters_data.append(
                {
                    "filename": filename,
                    "content": ch_content,
                    "name": abs_name,
                    "abstraction_index": abs_idx,
                    "num": i + 1,
                }
            )

        self._log_info("Prepared data for %d standard chapter files.", len(standard_chapters_data))
        return standard_chapters_data

    def _prepare_diagrams_chapter_data(
        self,
        shared: SharedState,  # Access shared state directly
        diagram_config: DiagramConfigDict,
        footer_info: FooterInfo,
        next_chapter_num: int,
    ) -> Optional[ChapterFileData]:
        """Prepare the data structure for the dedicated diagrams chapter.

        Checks configuration and shared state for generated diagrams (Class, Package, Sequence).
        If any relevant diagrams are found, it generates the Markdown content and
        returns the data structure for the diagrams chapter file.

        Args:
            shared: The shared state dictionary to retrieve diagram markups.
            diagram_config: The 'diagram_generation' configuration section.
            footer_info: FooterInfo object for adding the standard footer.
            next_chapter_num: The number to assign to this chapter.

        Returns:
            A dictionary representing the diagrams chapter file data (filename, content, etc.),
            or None if no diagrams are enabled or available.

        """
        content_parts: list[str] = []
        diagram_format = diagram_config.get("format", "mermaid")
        include_class = diagram_config.get("include_class_diagram", False)
        include_pkg = diagram_config.get("include_package_diagram", False)
        seq_config = diagram_config.get("include_sequence_diagrams", {})
        include_seq = seq_config.get("enabled", False)

        # Retrieve markups from shared state
        class_diag_markup = shared.get("class_diagram_markup")
        pkg_diag_markup = shared.get("package_diagram_markup")
        seq_diag_markups = shared.get("sequence_diagrams_markup")  # List or None
        identified_scenarios = shared.get("identified_scenarios", [])  # List or None/empty

        has_content = False

        # Add Class Diagram
        if include_class and class_diag_markup:
            content_parts.extend(
                [
                    "## Class Diagram\n",
                    f"```{diagram_format}\n{class_diag_markup}\n```\n",
                ]
            )
            self._log_info("Adding Class Diagram to diagrams chapter content.")
            has_content = True
        elif include_class:
            self._log_warning("Class diagram enabled but no markup found for diagrams chapter.")

        # Add Package Diagram
        if include_pkg and pkg_diag_markup:
            content_parts.extend(
                [
                    "## Package Dependencies\n",
                    f"```{diagram_format}\n{pkg_diag_markup}\n```\n",
                ]
            )
            self._log_info("Adding Package Diagram to diagrams chapter content.")
            has_content = True
        elif include_pkg:
            self._log_warning("Package diagram enabled but no markup found for diagrams chapter.")

        # Add Sequence Diagrams
        if include_seq and seq_diag_markups:
            content_parts.append("## Sequence Diagrams\n")
            num_markups = len(seq_diag_markups)
            num_scenarios = len(identified_scenarios) if isinstance(identified_scenarios, list) else 0

            if num_markups > 0 and num_markups != num_scenarios:
                logger.warning(
                    "Mismatch between number of sequence diagram markups (%d) and identified scenarios (%d). "
                    "Using generic titles if needed.",
                    num_markups,
                    num_scenarios,
                )

            for i, seq_markup in enumerate(seq_diag_markups):
                # Use identified scenario description as title if available
                scenario_title = (
                    identified_scenarios[i]
                    if isinstance(identified_scenarios, list) and i < num_scenarios
                    else f"Scenario {i + 1}"
                )
                content_parts.extend(
                    [
                        f"### {scenario_title}\n",  # Use scenario description as title
                        f"```{diagram_format}\n{seq_markup}\n```\n",
                    ]
                )
            self._log_info("Adding %d Sequence Diagram(s) to diagrams chapter content.", len(seq_diag_markups))
            has_content = True
        elif include_seq:
            self._log_warning("Sequence diagrams enabled but no markup found for diagrams chapter.")

        # Only return chapter data if content exists
        if has_content:
            full_content = f"# {DIAGRAMS_CHAPTER_TITLE}\n\n" + "\n".join(content_parts)
            footer = footer_info.format_footer()
            full_content += footer

            diagrams_filename = f"{next_chapter_num:02d}_{DIAGRAMS_FILENAME_BASE}.md"
            self._log_info("Prepared data for '%s' chapter (%s).", DIAGRAMS_CHAPTER_TITLE, diagrams_filename)
            return {
                "filename": diagrams_filename,
                "content": full_content,
                "name": DIAGRAMS_CHAPTER_TITLE,
                "num": next_chapter_num,
                "abstraction_index": -1,  # Indicates no specific abstraction
            }
        self._log_info("No diagrams enabled or available. Skipping diagrams chapter.")
        return None

    def _write_output_files(
        self,
        output_path: Path,
        index_content: str,
        all_chapter_files_data: list[ChapterFileData],  # Now includes diagrams chapter
    ) -> bool:
        """Write the index.md and all generated chapter files (including diagrams chapter).

        Args:
            output_path: Target directory Path object for the tutorial files.
            index_content: Complete Markdown content for the index.md file.
            all_chapter_files_data: List of dicts with 'filename' and 'content' for all chapters.

        Returns:
            True if the output directory was created and index/chapter write operations
            were attempted. False only if the base output directory creation fails.

        """
        try:
            output_path.mkdir(parents=True, exist_ok=True)
            resolved_path = output_path.resolve()
            self._log_info("Ensured output directory exists: %s", resolved_path)

            # Write index file
            index_filepath = resolved_path / "index.md"
            try:
                index_filepath.write_text(index_content, encoding="utf-8")
                self._log_info("Wrote index file: %s", index_filepath)
            except OSError as e:
                self._log_error("CRITICAL: Failed to write index file %s: %s", index_filepath, e, exc=e)
                return False

            # Write all chapter files
            write_success_flag = True
            for ch_info in all_chapter_files_data:
                fname = ch_info.get("filename")
                content = ch_info.get("content")
                chapter_name = ch_info.get("name", "Unknown")  # For logging

                if not (isinstance(fname, str) and fname and isinstance(content, str)):
                    logger.warning("Skipping chapter write due to invalid filename/content: %s", ch_info)
                    write_success_flag = False
                    continue

                ch_filepath = resolved_path / fname
                try:
                    ch_filepath.write_text(content, encoding="utf-8")
                    self._log_info("Wrote chapter file: %s ('%s')", ch_filepath, chapter_name)
                except OSError as e:
                    self._log_error("Failed to write chapter file %s ('%s'): %s", ch_filepath, chapter_name, e, exc=e)
                    write_success_flag = False

            if not write_success_flag:
                self._log_warning("One or more chapter file writes failed. Check previous logs.")

            return True

        except OSError as e:
            self._log_error("CRITICAL: Failed to create base output directory %s: %s", output_path, e, exc=e)
            return False

    def prep(self, shared: SharedState) -> CombinePrepResult:
        """Prepare all data, generate final content strings, and write output files.

        Args:
            shared: The shared state dictionary containing all processed data.

        Returns:
            True if the file writing operation was successfully initiated, False if a
            critical setup error occurred.

        """
        self._log_info("Starting tutorial combination and file writing...")
        final_output_path_str: Optional[str] = None
        write_operation_initiated = False

        try:
            # --- Retrieve data from shared state ---
            project_name: str = self._get_required_shared(shared, "project_name")
            output_base_dir_str: str = self._get_required_shared(shared, "output_dir")
            relationships_data: RelationshipsDict = self._get_required_shared(shared, "relationships")
            chapter_order: ChapterOrderList = self._get_required_shared(shared, "chapter_order")
            abstractions: AbstractionsList = self._get_required_shared(shared, "abstractions")
            chapters_content: ChapterContentList = self._get_required_shared(shared, "chapters")
            llm_config: dict[str, Any] = self._get_required_shared(shared, "llm_config")
            source_config: dict[str, Any] = self._get_required_shared(shared, "source_config")
            config: dict[str, Any] = self._get_required_shared(shared, "config")

            output_config = config.get("output", {})
            diagram_config: DiagramConfigDict = output_config.get("diagram_generation", {})
            repo_url: Optional[str] = shared.get("repo_url")
            local_dir: Optional[str] = shared.get("local_dir")
            rel_flowchart_markup = shared.get("relationship_flowchart_markup")  # Only this goes in index

            # --- Prepare Basic Info ---
            footer_info = FooterInfo(
                provider_name=llm_config.get("provider", "UnknownProvider"),
                model_name=llm_config.get("model", "UnknownModel"),
                is_local=llm_config.get("is_local_llm", False),
                source_language=source_config.get("language", "UnknownLanguage"),
            )
            safe_project_dir_name = sanitize_filename(project_name, allow_underscores=False).replace("_", "-")
            output_path = Path(output_base_dir_str) / safe_project_dir_name

            # --- Prepare Chapter Data (Standard Chapters + Diagrams Chapter) ---
            all_chapters_data: list[ChapterFileData] = self._prepare_standard_chapters_data(
                abstractions, chapter_order, chapters_content, footer_info
            )
            next_chap_num = len(all_chapters_data) + 1

            # Prepare and potentially add the diagrams chapter data
            diagrams_chapter_data = self._prepare_diagrams_chapter_data(
                shared=shared,  # Pass shared state to access diagrams
                diagram_config=diagram_config,
                footer_info=footer_info,
                next_chapter_num=next_chap_num,
            )
            if diagrams_chapter_data:
                all_chapters_data.append(diagrams_chapter_data)

            # --- Prepare Index Content ---
            index_context = IndexContext(
                project_name=project_name,
                relationships_data=relationships_data,
                footer_info=footer_info,
                repo_url=repo_url,
                local_dir=local_dir,
                relationship_flowchart_markup=rel_flowchart_markup,  # Only this diagram for index
                chapter_files_data=all_chapters_data,  # Pass list including diagrams chapter link
                diagram_config=diagram_config,
            )
            index_content = self._prepare_index_content(index_context)

            # --- Write Files ---
            write_successful = self._write_output_files(
                output_path,
                index_content,
                all_chapters_data,  # Write all chapters including diagrams
            )

            write_operation_initiated = True
            if write_successful:
                final_output_path_str = str(output_path.resolve())
                self._log_info("File writing process completed (may include partial errors).")
            else:
                self._log_error("File writing failed critically (e.g., output dir or index.md).")

        except (ValueError, KeyError) as e:
            self._log_error("Missing required data in shared state for combine operation: %s", e, exc=e)
            write_operation_initiated = False
        except OSError as e_os:
            self._log_error("Filesystem error during combine preparation: %s", e_os, exc=e_os)
            write_operation_initiated = False
        except Exception as e:
            self._log_error("Unexpected error during tutorial combination preparation: %s", e, exc=e)
            write_operation_initiated = False

        finally:
            shared["final_output_dir"] = final_output_path_str
            if final_output_path_str is None and write_operation_initiated:
                self._log_warning("Final output directory could not be set due to critical write errors.")
            elif not write_operation_initiated:
                self._log_warning("Combine preparation failed; final output directory not set.")

        return write_operation_initiated

    def exec(self, prep_res: CombinePrepResult) -> CombineExecResult:
        """Execute step for CombineTutorial (no-op)."""
        self._log_info("CombineTutorial exec step running (prep result: %s). No action taken.", prep_res)
        if not prep_res:
            self._log_warning("CombineTutorial prep step indicated failure or critical errors.")
        return None

    def post(self, shared: SharedState, prep_res: CombinePrepResult, exec_res: CombineExecResult) -> None:
        """Post-execution step for CombineTutorial. Logs the final completion status."""
        final_dir = shared.get("final_output_dir")
        status = "successfully" if prep_res and final_dir else "with errors (check logs for details)"
        self._log_info(f"CombineTutorial post-processing finished {status}. Final output directory: {final_dir}")


# End of src/sourcelens/nodes/combine.py
