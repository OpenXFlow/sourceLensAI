# Copyright (C) 2025 Jozef Darida (LinkedIn/Xing)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""Node responsible for generating an AI-powered project review."""

from typing import Any, Final, Optional

from typing_extensions import TypeAlias

from sourcelens.prompts.project_review_prompts import ProjectReviewPrompts
from sourcelens.utils.llm_api import LlmApiError, call_llm
from sourcelens.utils.validation import ValidationFailure, validate_yaml_dict

from .base_node import BaseNode, SLSharedState

ProjectReviewPrepResult: TypeAlias = dict[str, Any]
"""Type alias for the preparation result of GenerateProjectReview node.
   Contains keys like 'skip', 'project_name', 'abstractions_data', etc.
"""
ProjectReviewExecResult: TypeAlias = Optional[str]
"""Type alias for the execution result: Markdown content of the review or None."""

# Type aliases for data structures from shared_state
AbstractionsListInternal: TypeAlias = list[dict[str, Any]]
RelationshipsDictInternal: TypeAlias = dict[str, Any]
FileDataListInternal: TypeAlias = list[tuple[str, str]]
LlmConfigDictInternal: TypeAlias = dict[str, Any]
CacheConfigDictInternal: TypeAlias = dict[str, Any]
ConfigDictInternal: TypeAlias = dict[str, Any]
OutputConfigDictInternal: TypeAlias = dict[str, Any]

# Constants
MAX_REVIEW_SNIPPET_LEN: Final[int] = 200
PROJECT_REVIEW_SCHEMA: Final[dict[str, Any]] = {
    "type": "object",
    "properties": {
        "key_characteristics": {"type": "array", "items": {"type": "string"}},
        "areas_for_discussion": {"type": "array", "items": {"type": "string"}},
        "observed_patterns": {"type": "array", "items": {"type": "string"}},
        "coding_practice_observations": {"type": "array", "items": {"type": "string"}},  # Added this line
        "overall_summary": {"type": "string"},
    },
    "required": ["key_characteristics", "areas_for_discussion", "observed_patterns", "overall_summary"],
    # coding_practice_observations is optional, so not in 'required' unless we want to enforce it.
    # If we want it to be strictly optional and not fail if missing, we remove it from 'required'.
    # Since the prompt example marks it as '# Optional', let's not put it in 'required'.
    "additionalProperties": False,
}


class GenerateProjectReview(BaseNode[ProjectReviewPrepResult, ProjectReviewExecResult]):
    """Generate an AI-powered project review based on analyzed project data."""

    def _format_review_yaml_to_markdown(self, review_data: dict[str, Any], project_name: str) -> str:
        """Format the structured YAML data from LLM into Markdown.

        Args:
            review_data: The validated dictionary parsed from LLM's YAML response.
            project_name: The name of the project.

        Returns:
            A string containing the formatted Markdown for the project review chapter.
        """
        markdown_parts: list[str] = [f"# Project Review: {project_name}\n"]
        warning_text_part1 = (
            "> **Note:** This review is automatically generated by an AI (Large Language Model) "
            "based on an analysis of the project's abstractions, "
        )
        warning_text_part2 = (
            "relationships, and file structure. "
            "It is intended to provide high-level insights and stimulate discussion, "
            "not as a definitive expert assessment. Always use critical judgment when interpreting AI-generated content."
        )
        markdown_parts.append(f"{warning_text_part1}{warning_text_part2}\n")

        summary: str = str(review_data.get("overall_summary", "No overall summary provided."))
        markdown_parts.append(f"## AI-Generated Overall Summary\n\n{summary}\n")

        key_chars: Any = review_data.get("key_characteristics", [])
        if key_chars and isinstance(key_chars, list) and all(isinstance(item, str) for item in key_chars):
            markdown_parts.append("## Key Architectural Characteristics (AI-Observed)\n")
            for char_item in key_chars:
                markdown_parts.append(f"- {char_item}")
            markdown_parts.append("\n")

        areas_disc: Any = review_data.get("areas_for_discussion", [])
        if areas_disc and isinstance(areas_disc, list) and all(isinstance(item, str) for item in areas_disc):
            markdown_parts.append("## Potential Areas for Discussion (AI-Suggested)\n")
            for area_item in areas_disc:
                markdown_parts.append(f"- {area_item}")
            markdown_parts.append("\n")

        obs_patterns: Any = review_data.get("observed_patterns", [])
        if obs_patterns and isinstance(obs_patterns, list) and all(isinstance(item, str) for item in obs_patterns):
            markdown_parts.append("## Observed Patterns & Structural Notes (AI-Identified)\n")
            for pattern_item in obs_patterns:
                markdown_parts.append(f"- {pattern_item}")
            markdown_parts.append("\n")

        # New section for coding_practice_observations
        coding_obs: Any = review_data.get("coding_practice_observations", [])
        if coding_obs and isinstance(coding_obs, list) and all(isinstance(item, str) for item in coding_obs):
            markdown_parts.append("## Coding Practice Observations (AI-Noted)\n")
            for obs_item in coding_obs:
                markdown_parts.append(f"- {obs_item}")
            markdown_parts.append("\n")

        return "\n".join(markdown_parts)

    def prep(self, shared: SLSharedState) -> ProjectReviewPrepResult:
        """Prepare necessary data and context for generating the project review.

        Args:
            shared: The shared state dictionary.

        Returns:
            A dictionary containing data for the `exec` method, or indicating skip.
        """
        self._log_info("Preparing for project review generation.")
        try:
            config_any: Any = self._get_required_shared(shared, "config")
            config: ConfigDictInternal = config_any if isinstance(config_any, dict) else {}
            output_config_any: Any = config.get("output", {})
            output_config: OutputConfigDictInternal = output_config_any if isinstance(output_config_any, dict) else {}

            include_review_any: Any = output_config.get("include_project_review")
            include_review: bool = include_review_any if isinstance(include_review_any, bool) else False

            if not include_review:
                self._log_info("Project review generation is disabled in configuration. Skipping.")
                return {"skip": True, "reason": "Disabled in configuration"}

            prep_data: ProjectReviewPrepResult = {
                "skip": False,
                "project_name": str(self._get_required_shared(shared, "project_name")),
                "abstractions_data": self._get_required_shared(shared, "abstractions"),
                "relationships_data": self._get_required_shared(shared, "relationships"),
                "files_data": self._get_required_shared(shared, "files"),
                "language": str(shared.get("language", "unknown")),
                "llm_config": self._get_required_shared(shared, "llm_config"),
                "cache_config": self._get_required_shared(shared, "cache_config"),
            }
            if not isinstance(prep_data["abstractions_data"], list):
                raise TypeError("Abstractions data is not a list.")
            if not isinstance(prep_data["relationships_data"], dict):
                raise TypeError("Relationships data is not a dict.")
            if not isinstance(prep_data["files_data"], list):
                raise TypeError("Files data is not a list.")
            return prep_data
        except (ValueError, TypeError) as e_prep_val:
            self._log_error("Preparation for project review failed due to missing/invalid data: %s", e_prep_val)
            return {"skip": True, "reason": f"Data preparation error: {e_prep_val!s}"}

    def exec(self, prep_res: ProjectReviewPrepResult) -> ProjectReviewExecResult:
        """Generate the project review using an LLM.

        Args:
            prep_res: The dictionary returned by the `prep` method.

        Returns:
            A string containing the Markdown content for the project review,
            or None if skipped or an error occurred.
        """
        if prep_res.get("skip", True):
            reason_any: Any = prep_res.get("reason", "N/A")
            self._log_info("Skipping project review execution. Reason: %s", str(reason_any))
            return None

        project_name: str = prep_res["project_name"]
        self._log_info("Generating project review for '%s' using LLM...", project_name)

        abstractions_data: AbstractionsListInternal = prep_res["abstractions_data"]  # type: ignore[assignment]
        relationships_data: RelationshipsDictInternal = prep_res["relationships_data"]  # type: ignore[assignment]
        files_data: FileDataListInternal = prep_res["files_data"]  # type: ignore[assignment]
        language: str = prep_res["language"]
        llm_config: LlmConfigDictInternal = prep_res["llm_config"]  # type: ignore[assignment]
        cache_config: CacheConfigDictInternal = prep_res["cache_config"]  # type: ignore[assignment]

        prompt = ProjectReviewPrompts.format_project_review_prompt(
            project_name=project_name,
            abstractions_data=abstractions_data,
            relationships_data=relationships_data,
            files_data=files_data,
            language=language,
        )

        try:
            response_text = call_llm(prompt, llm_config, cache_config)
            validated_yaml_data = validate_yaml_dict(response_text, PROJECT_REVIEW_SCHEMA)
            markdown_content = self._format_review_yaml_to_markdown(validated_yaml_data, project_name)
            self._log_info("Successfully generated project review content.")
            return markdown_content
        except LlmApiError as e_llm:
            self._log_error("LLM call failed during project review generation: %s", e_llm, exc_info=True)
            return f"# Project Review: {project_name}\n\n> AI-generated review could not be created: LLM API error."
        except ValidationFailure as e_val:
            self._log_error("YAML validation failed for project review: %s", e_val)
            return f"# Project Review: {project_name}\n\n> AI-generated review validation failed: {e_val!s}"
        except (ValueError, TypeError, AttributeError, KeyError) as e_proc:
            self._log_error("Unexpected error during project review generation: %s", e_proc, exc_info=True)
            return f"# Project Review: {project_name}\n\n> Unexpected error generating review: {e_proc!s}"

    def post(self, shared: SLSharedState, prep_res: ProjectReviewPrepResult, exec_res: ProjectReviewExecResult) -> None:
        """Store the generated project review content in shared state.

        Args:
            shared: The shared state dictionary to update.
            prep_res: Result from the `prep` phase (used to check if skipped).
            exec_res: Markdown content of the project review, or None.
        """
        if prep_res.get("skip", True):
            shared["project_review_content"] = None
            self._log_info("Project review was skipped, 'project_review_content' set to None.")
            return

        shared["project_review_content"] = exec_res
        if exec_res and exec_res.strip():
            snippet = exec_res[:MAX_REVIEW_SNIPPET_LEN].replace("\n", " ")
            if len(exec_res) > MAX_REVIEW_SNIPPET_LEN:
                snippet += "..."
            self._log_info("Stored project review content in shared state (snippet: '%s').", snippet)
        else:
            self._log_warning("Project review content from exec was None or empty. Stored None.")


# End of src/sourcelens/nodes/n09_generate_project_review.py
