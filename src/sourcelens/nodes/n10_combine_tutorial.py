# Copyright (C) 2025 Jozef Darida (LinkedIn/Xing)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""Node responsible for combining generated tutorial components into final files."""

import contextlib
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Final, Literal, Optional, Union

from typing_extensions import TypeAlias

from sourcelens.utils._exceptions import LlmApiError
from sourcelens.utils.helpers import sanitize_filename

from .base_node import BaseNode, SLSharedContext

CombinePreparedInputs: TypeAlias = bool
CombineExecutionResult: TypeAlias = None

AbstractionItemInternal: TypeAlias = dict[str, Any]
AbstractionsListInternal: TypeAlias = list[AbstractionItemInternal]
RelationshipDetailInternal: TypeAlias = dict[str, Any]
RelationshipsDictInternal: TypeAlias = dict[str, Union[str, list[RelationshipDetailInternal]]]
ChapterOrderListInternal: TypeAlias = list[int]
ChapterContentListInternal: TypeAlias = list[str]

ChapterTypeLiteral: TypeAlias = Literal["standard", "diagrams", "source_index", "project_review"]
ChapterFileDataInternal: TypeAlias = dict[str, Any]
AllChaptersDataListInternal: TypeAlias = list[ChapterFileDataInternal]

DiagramMarkupInternal: TypeAlias = Optional[str]
SequenceDiagramsListInternal: TypeAlias = list[DiagramMarkupInternal]
DiagramConfigDictInternal: TypeAlias = dict[str, Any]
SequenceDiagramConfigDictInternal: TypeAlias = dict[str, Any]
IdentifiedScenarioListInternal: TypeAlias = list[str]

ConfigDictInternal: TypeAlias = dict[str, Any]
LlmConfigDictInternal: TypeAlias = dict[str, Any]
SourceConfigDictInternal: TypeAlias = dict[str, Any]
OutputConfigDictInternal: TypeAlias = dict[str, Any]
SharedDataForCombineInternal: TypeAlias = dict[str, Any]


DIAGRAMS_CHAPTER_TITLE: Final[str] = "Architecture Diagrams"
DIAGRAMS_FILENAME_BASE: Final[str] = "diagrams"
SOURCE_INDEX_CHAPTER_TITLE: Final[str] = "Code Inventory"
SOURCE_INDEX_FILENAME_BASE: Final[str] = "code_inventory"
PROJECT_REVIEW_CHAPTER_TITLE: Final[str] = "Project Review"
PROJECT_REVIEW_FILENAME_BASE: Final[str] = "project_review"
INDEX_FILENAME: Final[str] = "index.md"
FOOTER_SEPARATOR: Final[str] = "\n\n---\n\n*Generated by"
PREV_LINK_REGEX: Final[re.Pattern[str]] = re.compile(
    r"^\s*(?:> ?)?Previously, we looked at\s+\[.*?\]\(.*?\)\.?\s*$",
    re.IGNORECASE | re.MULTILINE,
)
NEXT_LINK_REGEX: Final[re.Pattern[str]] = re.compile(
    r"^\s*(?:> ?)?Next, we will examine\s+\[.*?\]\(.*?\)\.?\s*$",
    re.IGNORECASE | re.MULTILINE,
)
H1_HEADING_REGEX: Final[re.Pattern[str]] = re.compile(r"^\s*#\s+.*$", re.MULTILINE)

DEFAULT_PROJECT_NAME_COMBINE: Final[str] = "sourcelens_tutorial_output"
DEFAULT_OUTPUT_DIR_COMBINE: Final[str] = "output"
FOOTER_PROVIDER_DEFAULT: Final[str] = "N/A"
FOOTER_MODEL_DEFAULT: Final[str] = "N/A"
FOOTER_SOURCE_LANG_DEFAULT: Final[str] = "N/A"
FILENAME_CHAPTER_PREFIX_WIDTH_COMBINE: Final[int] = 2
LOG_MARKUP_SNIPPET_LEN_COMBINE: Final[int] = 200
MAX_INT_FOR_SORTING: Final[int] = sys.maxsize


@dataclass(frozen=True)
class FooterInfo:
    """Encapsulate information needed to generate the file footer."""

    provider_name: str
    model_name: str
    is_local: bool
    source_language: str

    def format_footer(self) -> str:
        """Generate the formatted footer string."""
        location: str = "(local)" if self.is_local else "(cloud)"
        repo_link: str = "https://github.com/darijo2yahoocom/sourceLensAI"
        part1: str = f"{FOOTER_SEPARATOR} [SourceLens AI]({repo_link}) "
        part2: str = f"using LLM: `{self.provider_name}` {location} "
        part3: str = f"- model: `{self.model_name}` | Language Profile: `{self.source_language}`*"
        return part1 + part2 + part3


@dataclass(frozen=True)
class IndexContext:
    """Encapsulate context needed to prepare the index.md file content."""

    project_name: str
    relationships_data: RelationshipsDictInternal
    footer_info: FooterInfo
    repo_url: Optional[str] = None
    local_dir: Optional[str] = None
    relationship_flowchart_markup: DiagramMarkupInternal = None
    chapter_files_data: AllChaptersDataListInternal = field(default_factory=list)
    diagram_config: DiagramConfigDictInternal = field(default_factory=dict)
    include_rel_flowchart: bool = field(init=False)

    def __post_init__(self) -> None:
        """Set derived diagram flags after initialization."""
        include_flag_val: Any = self.diagram_config.get("include_relationship_flowchart", False)
        include_flag: bool = include_flag_val if isinstance(include_flag_val, bool) else False
        object.__setattr__(self, "include_rel_flowchart", include_flag)


@dataclass
class DiagramMarkupContext:
    """Context for adding diagram markup to a content list."""

    content_parts: list[str]
    markup: DiagramMarkupInternal
    diagram_title: str
    diagram_description: str
    diagram_format: str
    log_message: str


class CombineTutorial(BaseNode[CombinePreparedInputs, CombineExecutionResult]):
    """Combine generated tutorial components into final Markdown files."""

    def _get_special_chapter_base_name(self, chapter_type: ChapterTypeLiteral) -> str:
        """Return the base filename for a special chapter type.

        Args:
            chapter_type: The type of the special chapter.

        Returns:
            The base filename string for that chapter type.
        """
        if chapter_type == "diagrams":
            return DIAGRAMS_FILENAME_BASE
        if chapter_type == "source_index":
            return SOURCE_INDEX_FILENAME_BASE
        if chapter_type == "project_review":
            return PROJECT_REVIEW_FILENAME_BASE
        self._log_warning("Unknown special chapter type '%s' for filename base generation.", chapter_type)
        return "special_chapter"

    def _add_diagram_markup(self, ctx: DiagramMarkupContext) -> bool:
        """Add a diagram's markup and description to content parts."""
        if ctx.markup and ctx.markup.strip():
            ctx.content_parts.append(f"## {ctx.diagram_title}\n")
            ctx.content_parts.append(f"{ctx.diagram_description}\n")
            ctx.content_parts.append(f"```{ctx.diagram_format}\n{ctx.markup.strip()}\n```\n")
            self._log_info(ctx.log_message)
            return True
        self._log_warning("Attempted to add diagram '%s', but markup was empty.", ctx.diagram_title)
        return False

    def _add_sequence_diagrams_markup(
        self,
        content_parts: list[str],
        seq_diag_markups: SequenceDiagramsListInternal,
        identified_scenarios: IdentifiedScenarioListInternal,
        diagram_format: str,
    ) -> bool:
        """Add multiple sequence diagrams with descriptions to content parts list."""
        valid_markups_with_scenarios: list[tuple[str, str]] = []
        for i, markup_item in enumerate(seq_diag_markups):
            if markup_item and markup_item.strip():
                scenario_desc = f"Scenario {i + 1}"
                if i < len(identified_scenarios) and identified_scenarios[i] and identified_scenarios[i].strip():
                    scenario_desc = identified_scenarios[i]
                valid_markups_with_scenarios.append((scenario_desc, markup_item.strip()))

        if not valid_markups_with_scenarios:
            self._log_warning("No valid sequence diagram markups to add.")
            return False

        if not any("## Sequence Diagrams" in part for part in content_parts if part.startswith("## ")):
            content_parts.append("## Sequence Diagrams\n")
            desc_text_l1 = "These diagrams illustrate various interaction scenarios within the application, "
            desc_text_l2 = (
                "showcasing the sequence of operations between different components for specific use cases.\n"
            )
            content_parts.append(desc_text_l1 + desc_text_l2)

        for scenario_desc, seq_markup in valid_markups_with_scenarios:
            content_parts.append(f"### {scenario_desc}\n")
            content_parts.append(f"```{diagram_format}\n{seq_markup}\n```\n")

        self._log_info("Adding %d Sequence Diagram(s) markup.", len(valid_markups_with_scenarios))
        return True

    def _add_prev_link(self, chapter_data: ChapterFileDataInternal, prev_link_text: Optional[str]) -> None:
        """Ensure the 'Previously...' navigation link exists once before H1 heading."""
        if not prev_link_text or not prev_link_text.strip():
            return
        content: str = str(chapter_data.get("content", "") or "")
        chapter_num_str = str(chapter_data.get("num", "Unknown"))
        content, num_removed = PREV_LINK_REGEX.subn("", content)
        if num_removed > 0:
            self._log_info("Removed %d 'Previously...' link(s) from ch %s.", num_removed, chapter_num_str)
        content = re.sub(r"^\s*\n", "", content, flags=re.MULTILINE)
        content = re.sub(r"\n{3,}", "\n\n", content).strip()
        h1_match = H1_HEADING_REGEX.search(content)
        if h1_match:
            start_index = h1_match.start()
            prefix_newline = "\n" if start_index > 0 and not content[:start_index].isspace() else ""
            new_content_parts = [
                content[:start_index].rstrip(),
                prefix_newline,
                f"\n\n{prev_link_text}\n\n",
                content[start_index:],
            ]
            content = "".join(filter(None, new_content_parts))
        else:
            content = f"{prev_link_text}\n\n{content}"
            self._log_warning("No H1 in ch %s. Added 'Previously...' link at start.", chapter_num_str)
        chapter_data["content"] = content.strip()

    def _add_next_link(self, chapter_data: ChapterFileDataInternal, next_link_text: Optional[str]) -> None:
        """Ensure the 'Next...' navigation link exists once at the end of chapter content."""
        if not next_link_text or not next_link_text.strip():
            return
        content: str = str(chapter_data.get("content", "") or "")
        chapter_num_str = str(chapter_data.get("num", "Unknown"))
        content, num_removed = NEXT_LINK_REGEX.subn("", content)
        if num_removed > 0:
            self._log_info("Removed %d 'Next...' link(s) from ch %s.", num_removed, chapter_num_str)
        content = re.sub(r"\n{3,}", "\n\n", content).strip()
        content += f"\n\n{next_link_text}" if content else next_link_text
        chapter_data["content"] = content.strip()

    def _add_navigation_links(self, all_chapters_data: AllChaptersDataListInternal, index_filename: str) -> None:
        """Add or update 'Previously...' and 'Next...' links in all chapters."""
        num_all_chapters = len(all_chapters_data)
        if num_all_chapters == 0:
            self._log_warning("No chapters found to add navigation links.")
            return
        for i, chapter_data in enumerate(all_chapters_data):
            prev_link_text: Optional[str] = None
            if i == 0:
                prev_link_text = f"Previously, we looked at the [Project Overview]({index_filename})."
            elif i > 0:
                prev_ch = all_chapters_data[i - 1]
                p_name_any, p_file_any = prev_ch.get("name"), prev_ch.get("filename")
                if (
                    isinstance(p_name_any, str)
                    and p_name_any.strip()
                    and isinstance(p_file_any, str)
                    and p_file_any.strip()
                ):
                    prev_link_text = f"Previously, we looked at [{p_name_any.strip()}]({p_file_any.strip()})."
                else:
                    log_msg = f"Could not create 'previous' link for ch {chapter_data.get('num', i + 1)}."
                    self._log_warning(log_msg)
            self._add_prev_link(chapter_data, prev_link_text)

            next_link_text: Optional[str] = None
            if i < num_all_chapters - 1:
                next_ch = all_chapters_data[i + 1]
                n_name_any, n_file_any = next_ch.get("name"), next_ch.get("filename")
                if (
                    isinstance(n_name_any, str)
                    and n_name_any.strip()
                    and isinstance(n_file_any, str)
                    and n_file_any.strip()
                ):
                    next_link_text = f"Next, we will examine [{n_name_any.strip()}]({n_file_any.strip()})."
                else:
                    log_msg = f"Could not create 'next' link for ch {chapter_data.get('num', i + 1)}."
                    self._log_warning(log_msg)
            self._add_next_link(chapter_data, next_link_text)

    def _add_footers(self, all_chapters_data: AllChaptersDataListInternal, footer_text: str) -> None:
        """Append the standard footer to all chapter contents."""
        clean_footer_text: str = footer_text.strip()
        if not clean_footer_text:
            self._log_warning("Footer text is empty, not adding footers.")
            return
        for chapter_data in all_chapters_data:
            current_content: str = str(chapter_data.get("content", "") or "")
            if FOOTER_SEPARATOR in current_content:
                current_content = current_content.split(FOOTER_SEPARATOR, 1)[0]
            current_content = current_content.rstrip()
            chapter_data["content"] = f"{current_content}\n{footer_text}" if current_content else footer_text.lstrip()

    def _prepare_index_header(self, context: IndexContext) -> list[str]:
        """Prepare the header section of the index.md."""
        summary_raw: Any = context.relationships_data.get("summary", f"Tutorial for {context.project_name}.")
        summary: str = str(summary_raw or f"Tutorial for {context.project_name}.")
        header_parts: list[str] = [f"# Tutorial: {context.project_name}\n\n{summary}\n"]
        source_info: str = ""
        if context.repo_url:
            source_info = f"**Source Repository:** [{context.repo_url}]({context.repo_url})"
        elif context.local_dir:
            try:
                resolved_local_dir = Path(str(context.local_dir)).resolve(strict=False)
                source_info = f"**Source Directory:** `{resolved_local_dir}`"
            except (OSError, TypeError, ValueError) as e:
                self._log_warning("Cannot resolve local_dir '%s': %s", context.local_dir, e)
                source_info = f"**Source Directory:** `{str(context.local_dir)}` (resolution failed)"
        if source_info:
            header_parts.append(f"{source_info}\n")
        return header_parts

    def _prepare_index_diagram(self, context: IndexContext) -> list[str]:
        """Prepare the relationship diagram section of the index.md."""
        diagram_parts: list[str] = []
        diagram_format = str(context.diagram_config.get("format", "mermaid"))
        markup_log_snippet = "None"
        if context.relationship_flowchart_markup:
            markup_str = str(context.relationship_flowchart_markup)
            markup_log_snippet = markup_str[:LOG_MARKUP_SNIPPET_LEN_COMBINE]
            if len(markup_str) > LOG_MARKUP_SNIPPET_LEN_COMBINE:
                markup_log_snippet += "..."

        self._logger.debug(
            "_prepare_index_diagram: include_rel_flowchart=%s, markup snippet='%s', type=%s, is_truthy=%s",
            context.include_rel_flowchart,
            markup_log_snippet,
            type(context.relationship_flowchart_markup).__name__,
            bool(context.relationship_flowchart_markup and str(context.relationship_flowchart_markup).strip()),
        )
        if context.include_rel_flowchart and context.relationship_flowchart_markup:
            markup = str(context.relationship_flowchart_markup).strip()
            if markup:
                diagram_parts.extend(["## Abstraction Relationships\n", f"```{diagram_format}\n{markup}\n```\n"])
                self._log_info("Embedding relationship flowchart into index.md.")
            else:
                self._log_warning("Rel flowchart enabled for index.md, but markup was empty string after strip().")
        elif context.include_rel_flowchart:
            self._log_warning("Rel flowchart enabled for index.md, but no markup provided.")
        return diagram_parts

    def _get_chapter_sort_key(self, ch_data: ChapterFileDataInternal) -> tuple[int, int, str]:
        """Provide a sort key for chapters."""
        ch_type: ChapterTypeLiteral = ch_data.get("chapter_type", "standard")  # type: ignore[assignment]
        abs_index_any: Any = ch_data.get("abstraction_index")

        final_num_any: Any = ch_data.get("num")
        final_num = int(final_num_any) if isinstance(final_num_any, int) and final_num_any > 0 else MAX_INT_FOR_SORTING

        if final_num != MAX_INT_FOR_SORTING:
            return 0, final_num, str(ch_data.get("name", ""))

        primary_sort_key: int
        if ch_type == "standard" and isinstance(abs_index_any, int) and abs_index_any >= 0:
            primary_sort_key = abs_index_any
        else:
            primary_sort_key = MAX_INT_FOR_SORTING

        special_order: dict[ChapterTypeLiteral, int] = {
            "diagrams": 10001,
            "source_index": 10002,
            "project_review": 10003,
        }
        secondary_sort_key = 0 if ch_type == "standard" else special_order.get(ch_type, 19999)

        return secondary_sort_key, primary_sort_key, str(ch_data.get("name", ""))

    def _prepare_index_chapters(self, context: IndexContext) -> list[str]:
        """Prepare the chapters listing section of the index.md."""
        chapter_parts: list[str] = ["## Chapters\n"]
        sorted_chapters_for_index: AllChaptersDataListInternal
        try:
            sorted_chapters_for_index = sorted(
                context.chapter_files_data, key=lambda x: x.get("num", MAX_INT_FOR_SORTING)
            )
        except (TypeError, ValueError) as e_sort:
            self._log_warning("Cannot sort chapters by final 'num' for index; using provided order. Error: %s", e_sort)
            sorted_chapters_for_index = context.chapter_files_data

        chapter_links: list[str] = []
        for ch_data in sorted_chapters_for_index:
            num_val, name_val, fname_val = (ch_data.get("num"), ch_data.get("name"), ch_data.get("filename"))
            if (
                isinstance(num_val, int)
                and num_val > 0
                and isinstance(name_val, str)
                and name_val.strip()
                and isinstance(fname_val, str)
                and fname_val.strip()
            ):
                chapter_links.append(f"{num_val}. [{name_val.strip()}]({fname_val.strip()})")
            else:
                self._log_warning("Skipping chapter link in index.md due to invalid data: %s", ch_data)
        chapter_parts.append("\n".join(chapter_links) if chapter_links else "No chapters available.")
        return chapter_parts

    def _prepare_index_content(self, context: IndexContext) -> str:
        """Prepare the full Markdown content for the index.md file."""
        self._log_info("Preparing index.md content for project '%s'...", context.project_name)
        content_parts: list[str] = self._prepare_index_header(context)
        content_parts.extend(self._prepare_index_diagram(context))
        content_parts.extend(self._prepare_index_chapters(context))
        return "\n".join(content_parts)

    def _prepare_standard_chapters_data(
        self,
        abstractions: AbstractionsListInternal,
        chapter_order: ChapterOrderListInternal,
        chapters_content: ChapterContentListInternal,
    ) -> AllChaptersDataListInternal:
        """Prepare initial data structure for standard chapter files."""
        std_chapters_data: AllChaptersDataListInternal = []
        num_abstractions = len(abstractions)
        effective_count = min(len(chapter_order), len(chapters_content))

        if len(chapter_order) != len(chapters_content):
            self._log_warning(
                "Ch order count (%d) != content count (%d). Processing %d.",
                len(chapter_order),
                len(chapters_content),
                effective_count,
            )

        abs_idx_to_order_pos = {abs_idx: i for i, abs_idx in enumerate(chapter_order)}

        for i in range(effective_count):
            abs_idx = chapter_order[i]
            if not (0 <= abs_idx < num_abstractions):
                self._log_warning("Invalid abs_idx %d at order pos %d. Skipping.", abs_idx, i)
                continue
            abs_item: AbstractionItemInternal = abstractions[abs_idx]
            name_raw: Any = abs_item.get("name", f"Concept {i + 1}")
            name: str = str(name_raw).strip() if isinstance(name_raw, str) and name_raw.strip() else f"Concept {i + 1}"
            pedagogical_order_num = abs_idx_to_order_pos.get(abs_idx, MAX_INT_FOR_SORTING - 1) + 1

            std_chapters_data.append(
                {
                    "content": str(chapters_content[i] or ""),
                    "name": name,
                    "abstraction_index": abs_idx,
                    "chapter_type": "standard",
                    "filename": "",
                    "num": pedagogical_order_num,
                }
            )
        self._log_info("Prepared data for %d standard chapters.", len(std_chapters_data))
        std_chapters_data.sort(key=lambda x: x.get("num", MAX_INT_FOR_SORTING))
        return std_chapters_data

    def _prepare_special_chapter_data(
        self,
        content_key_or_direct_content: str,
        title: str,
        chapter_type: ChapterTypeLiteral,
        *,
        shared_context: Optional[SLSharedContext] = None,
        is_direct_content: bool = False,
    ) -> Optional[ChapterFileDataInternal]:
        """Prepare data structure for a special chapter.

        Content can be a key to shared_context or direct markdown string.

        Args:
            content_key_or_direct_content: Key in shared_context or direct content.
            title: The title of this special chapter.
            chapter_type: The type of the special chapter.
            shared_context: The shared context dictionary (needed if not direct_content).
            is_direct_content: If True, content_key_or_direct_content is the content itself.

        Returns:
            A ChapterFileDataInternal dictionary if content is found, else None.
        """
        content_val_str: Optional[str] = None
        if is_direct_content:
            content_val_str = content_key_or_direct_content
        elif shared_context:
            content_val_any: Any = shared_context.get(content_key_or_direct_content)
            if isinstance(content_val_any, str):
                content_val_str = content_val_any

        log_prefix = f"_prepare_special_chapter_data ({chapter_type})"
        content_snippet = content_key_or_direct_content[:50]
        self._logger.debug(
            "%s: key/content='%.50s...', type: %s, empty: %s",
            log_prefix,
            content_snippet,
            type(content_val_str).__name__,
            not bool(content_val_str and content_val_str.strip()),
        )
        if not (content_val_str and content_val_str.strip()):
            self._log_info(
                "No valid content for '%s' chapter (key/content: '%.50s...').", chapter_type, content_snippet
            )
            return None
        self._log_info("'%s' chapter data prepared (len: %d).", chapter_type.capitalize(), len(content_val_str))

        special_indices_map: dict[ChapterTypeLiteral, int] = {
            "diagrams": -2000,
            "source_index": -3000,
            "project_review": -4000,
        }
        return {
            "filename": "",
            "content": content_val_str,
            "name": title,
            "num": -1,
            "abstraction_index": special_indices_map.get(chapter_type, -5000),
            "chapter_type": chapter_type,
        }

    def _add_and_assign_numbers_to_special_chapters(
        self,
        all_chapters_list: AllChaptersDataListInternal,
        shared_context: SLSharedContext,
        output_config: OutputConfigDictInternal,
        diagram_config: DiagramConfigDictInternal,
        starting_chapter_number: int,
    ) -> int:
        """Add special chapters and assign their chapter numbers sequentially."""
        current_num = starting_chapter_number

        if any(
            diagram_config.get(f"include_{d_type}", False)
            for d_type in ["relationship_flowchart", "class_diagram", "package_diagram"]
        ) or (
            isinstance(diagram_config.get("include_sequence_diagrams"), dict)
            and diagram_config["include_sequence_diagrams"].get("enabled")
        ):
            diagram_content_str = self._create_diagrams_chapter_content(shared_context, diagram_config)
            if diagram_content_str:
                # Pass content directly
                diagram_chapter_data = self._prepare_special_chapter_data(
                    diagram_content_str, DIAGRAMS_CHAPTER_TITLE, "diagrams", is_direct_content=True
                )
                if diagram_chapter_data:
                    diagram_chapter_data["num"] = current_num
                    all_chapters_list.append(diagram_chapter_data)
                    current_num += 1
            else:
                self._log_info("Diagrams chapter content was empty, not adding chapter.")

        if bool(output_config.get("include_source_index", False)):
            src_idx_chapter = self._prepare_special_chapter_data(
                "source_index_content", SOURCE_INDEX_CHAPTER_TITLE, "source_index", shared_context=shared_context
            )
            if src_idx_chapter:
                src_idx_chapter["num"] = current_num
                all_chapters_list.append(src_idx_chapter)
                current_num += 1

        if bool(output_config.get("include_project_review", False)):
            proj_rev_chapter = self._prepare_special_chapter_data(
                "project_review_content", PROJECT_REVIEW_CHAPTER_TITLE, "project_review", shared_context=shared_context
            )
            if proj_rev_chapter:
                proj_rev_chapter["num"] = current_num
                all_chapters_list.append(proj_rev_chapter)
                current_num += 1
        return current_num

    def _assemble_chapters(
        self, shared_context: SLSharedContext, data: SharedDataForCombineInternal
    ) -> AllChaptersDataListInternal:
        """Assemble all chapter types, sort them, and assign final numbers/filenames."""
        self._log_info("Assembling all chapter data...")
        cfg: ConfigDictInternal = data.get("config", {})  # type: ignore[assignment]
        out_cfg: OutputConfigDictInternal = cfg.get("output", {})  # type: ignore[assignment]
        diag_cfg: DiagramConfigDictInternal = out_cfg.get("diagram_generation", {})  # type: ignore[assignment]

        abstractions: AbstractionsListInternal = data.get("abstractions", [])  # type: ignore[assignment]
        chapter_order: ChapterOrderListInternal = data.get("chapter_order", [])  # type: ignore[assignment]
        chapters_content: ChapterContentListInternal = data.get("chapters_content", [])  # type: ignore[assignment]

        all_assembled_chapters = self._prepare_standard_chapters_data(abstractions, chapter_order, chapters_content)

        for i, chap_data in enumerate(
            all_assembled_chapters
        ):  # Standard chapters are already sorted by pedagogical order
            chap_data["num"] = i + 1

        next_available_chapter_num = len(all_assembled_chapters) + 1
        self._add_and_assign_numbers_to_special_chapters(
            all_assembled_chapters, shared_context, out_cfg, diag_cfg, next_available_chapter_num
        )

        all_assembled_chapters.sort(key=lambda x: x.get("num", MAX_INT_FOR_SORTING))

        for chapter_info in all_assembled_chapters:  # Filenames based on final sorted 'num'
            name_raw: str = str(chapter_info.get("name", f"chapter-{chapter_info['num']}"))
            ch_type: ChapterTypeLiteral = chapter_info.get("chapter_type", "standard")  # type: ignore[assignment]

            name_base = (
                self._get_special_chapter_base_name(ch_type)
                if ch_type in ["diagrams", "source_index", "project_review"]
                else (sanitize_filename(name_raw) or f"chapter-{chapter_info['num']}")
            )

            num_val = chapter_info["num"]
            chapter_info["filename"] = f"{num_val:0{FILENAME_CHAPTER_PREFIX_WIDTH_COMBINE}d}_{name_base}.md"

        self._log_info("Assembled and numbered %d chapters for final output.", len(all_assembled_chapters))
        return all_assembled_chapters

    def _create_diagrams_chapter_content(
        self, shared_context: SLSharedContext, diagram_config: DiagramConfigDictInternal
    ) -> Optional[str]:
        """Create the content for the diagrams chapter by combining individual diagram markups."""
        content_parts: list[str] = [f"# {DIAGRAMS_CHAPTER_TITLE}\n"]
        fmt = str(diagram_config.get("format", "mermaid"))
        proj: str = str(shared_context.get("project_name", DEFAULT_PROJECT_NAME_COMBINE))
        has_any_diagram_content = False

        if bool(diagram_config.get("include_class_diagram", False)):
            markup_val = shared_context.get("class_diagram_markup")
            markup: DiagramMarkupInternal = str(markup_val) if isinstance(markup_val, str) else None
            desc_class = f"Key classes and their relationships in **{proj}**."
            if self._add_diagram_markup(
                DiagramMarkupContext(
                    content_parts, markup, "Class Diagram", desc_class, fmt, "Adding Class Diagram to diagrams chapter."
                )
            ):
                has_any_diagram_content = True

        if bool(diagram_config.get("include_package_diagram", False)):
            markup_val = shared_context.get("package_diagram_markup")
            markup_pkg: DiagramMarkupInternal = str(markup_val) if isinstance(markup_val, str) else None
            desc_pkg = f"High-level module and package structure of **{proj}**."
            if self._add_diagram_markup(
                DiagramMarkupContext(
                    content_parts,
                    markup_pkg,
                    "Package Dependencies",
                    desc_pkg,
                    fmt,
                    "Adding Package Diagram to diagrams chapter.",
                )
            ):
                has_any_diagram_content = True

        seq_cfg_any: Any = diagram_config.get("include_sequence_diagrams", {})
        seq_cfg: SequenceDiagramConfigDictInternal = seq_cfg_any if isinstance(seq_cfg_any, dict) else {}
        if bool(seq_cfg.get("enabled", False)):
            scenarios_raw: Any = shared_context.get("identified_scenarios", [])
            markups_list_any: Any = shared_context.get("sequence_diagrams_markup", [])

            markups_list: SequenceDiagramsListInternal = (
                [str(m) if isinstance(m, str) else None for m in markups_list_any]
                if isinstance(markups_list_any, list)
                else []
            )

            scenarios_list: IdentifiedScenarioListInternal = (
                [str(s) for s in scenarios_raw if isinstance(s, str) and s.strip()]
                if isinstance(scenarios_raw, list)
                else []
            )

            if self._add_sequence_diagrams_markup(content_parts, markups_list, scenarios_list, fmt):
                has_any_diagram_content = True

        return "\n".join(content_parts) if has_any_diagram_content else None

    def _process_and_write_tutorial_files(
        self,
        shared_context: SLSharedContext,
        data: SharedDataForCombineInternal,
        footer_info: FooterInfo,
        output_path_obj: Path,
    ) -> bool:
        """Orchestrate chapter assembly, formatting, and file writing."""
        all_chapters = self._assemble_chapters(shared_context, data)

        rel_flow_markup_val: Any = data.get("relationship_flowchart_markup")
        rel_flow_markup: DiagramMarkupInternal = (
            str(rel_flow_markup_val) if isinstance(rel_flow_markup_val, str) else None
        )

        if not all_chapters and not (rel_flow_markup and rel_flow_markup.strip()):
            self._log_warning("No content to combine (no chapters and no main flowchart). Skipping file writes.")
            shared_context["final_output_dir"] = str(output_path_obj.resolve())
            return True

        footer_str = footer_info.format_footer()
        self._add_navigation_links(all_chapters, INDEX_FILENAME)
        self._add_footers(all_chapters, footer_str)

        cfg_any: Any = data.get("config", {})
        cfg: ConfigDictInternal = cfg_any if isinstance(cfg_any, dict) else {}
        out_cfg_any: Any = cfg.get("output", {})
        out_cfg: OutputConfigDictInternal = out_cfg_any if isinstance(out_cfg_any, dict) else {}
        diag_cfg: DiagramConfigDictInternal = (
            out_cfg.get("diagram_generation", {}) if isinstance(out_cfg.get("diagram_generation"), dict) else {}
        )

        idx_ctx = IndexContext(
            project_name=str(data.get("project_name", DEFAULT_PROJECT_NAME_COMBINE)),
            relationships_data=data.get("relationships_data", {}),  # type: ignore[arg-type]
            footer_info=footer_info,
            repo_url=str(data.get("repo_url")) if isinstance(data.get("repo_url"), str) else None,
            local_dir=str(data.get("local_dir")) if isinstance(data.get("local_dir"), str) else None,
            relationship_flowchart_markup=rel_flow_markup,
            chapter_files_data=all_chapters,
            diagram_config=diag_cfg,
        )
        index_md_content = self._prepare_index_content(idx_ctx)
        if FOOTER_SEPARATOR not in index_md_content:
            index_md_content = index_md_content.rstrip() + f"\n{footer_str}"
        return self._write_output_files(output_path_obj, index_md_content, all_chapters)

    def _write_output_files(
        self, output_path: Path, index_content: str, all_chapter_files_data: AllChaptersDataListInternal
    ) -> bool:
        """Write the index.md and all generated chapter files to disk."""
        try:
            output_path.mkdir(parents=True, exist_ok=True)
            self._log_info("Ensured output directory exists: %s", output_path.resolve())
        except OSError as e_dir:
            self._log_error("CRITICAL: Failed to create output directory %s: %s", output_path, e_dir, exc_info=True)
            raise
        index_filepath = output_path / INDEX_FILENAME
        try:
            index_filepath.write_text(index_content, encoding="utf-8")
            self._log_info("Wrote index file: %s", index_filepath)
        except OSError as e_idx:
            self._log_error("CRITICAL: Failed to write index file %s: %s", index_filepath, e_idx, exc_info=True)
            return False
        all_writes_ok = True
        self._log_info("Attempting to write %d chapter files.", len(all_chapter_files_data))
        for ch_info in all_chapter_files_data:
            fname_val = str(ch_info.get("filename", ""))
            content_val = str(ch_info.get("content", ""))
            ch_name = str(ch_info.get("name", "Unknown Chapter"))

            if not (fname_val.strip() and content_val.strip()):
                self._log_warning("Skipping file write for ch '%s': invalid filename or empty content.", ch_name)
                if not fname_val.strip():
                    all_writes_ok = False
                continue
            ch_filepath = output_path / fname_val
            try:
                ch_filepath.write_text(content_val, encoding="utf-8")
                self._log_info("Wrote chapter file: %s (Name: '%s')", ch_filepath, ch_name)
            except OSError as e_ch:
                log_err_msg = f"Failed to write ch file {ch_filepath} (Name: '{ch_name}'): {e_ch!s}"
                self._log_error(log_err_msg, exc_info=True)
                all_writes_ok = False
        if not all_writes_ok:
            self._log_warning("One or more chapter file writes failed. Please check logs.")
        return all_writes_ok

    def _retrieve_shared_data(self, shared_context: SLSharedContext) -> SharedDataForCombineInternal:
        """Retrieve all necessary data from shared context for combination logic."""
        self._logger.debug("--- Retrieving data from shared_context for CombineTutorial ---")
        keys_to_log = [
            "abstractions",
            "chapter_order",
            "chapters",
            "relationship_flowchart_markup",
            "project_review_content",
            "source_index_content",
        ]
        for key in keys_to_log:
            value = shared_context.get(key)
            value_type = type(value).__name__
            value_len_str = "N/A"
            # SIM105: Use `contextlib.suppress` instead of `try-except-pass`
            with contextlib.suppress(TypeError):  # Handles len(None) or non-sized types
                if hasattr(value, "__len__"):
                    value_len_str = str(len(value))  # type: ignore[arg-type]

            value_snippet = (
                str(value)[:LOG_MARKUP_SNIPPET_LEN_COMBINE] + "..."
                if value and len(str(value)) > LOG_MARKUP_SNIPPET_LEN_COMBINE
                else str(value)
            )
            self._logger.debug(
                "Shared key '%s': type=%s, len=%s, snippet='%s'",
                key,
                value_type,
                value_len_str,
                value_snippet if value is not None else "None",
            )

        data: SharedDataForCombineInternal = {
            "project_name": str(self._get_required_shared(shared_context, "project_name")),
            "output_base_dir": str(self._get_required_shared(shared_context, "output_dir")),
            "relationships_data": self._get_required_shared(shared_context, "relationships"),
            "chapter_order": self._get_required_shared(shared_context, "chapter_order"),
            "abstractions": self._get_required_shared(shared_context, "abstractions"),
            "chapters_content": self._get_required_shared(shared_context, "chapters"),
            "llm_config": self._get_required_shared(shared_context, "llm_config"),
            "source_config": self._get_required_shared(shared_context, "source_config"),
            "config": self._get_required_shared(shared_context, "config"),
            "repo_url": shared_context.get("repo_url"),
            "local_dir": shared_context.get("local_dir"),
            "relationship_flowchart_markup": shared_context.get("relationship_flowchart_markup"),
            "class_diagram_markup": shared_context.get("class_diagram_markup"),
            "package_diagram_markup": shared_context.get("package_diagram_markup"),
            "sequence_diagrams_markup": shared_context.get("sequence_diagrams_markup", []),
            "identified_scenarios": shared_context.get("identified_scenarios", []),
            "source_index_content": shared_context.get("source_index_content"),
            "project_review_content": shared_context.get("project_review_content"),
        }
        self._logger.debug("--- Finished retrieving data from shared_context ---")
        return data

    def _initialize_combine_data(
        self, shared_context: SLSharedContext
    ) -> tuple[SharedDataForCombineInternal, FooterInfo, Path]:
        """Initialize data structures needed for combining the tutorial."""
        data = self._retrieve_shared_data(shared_context)
        llm_cfg_any: Any = data.get("llm_config", {})
        src_cfg_any: Any = data.get("source_config", {})
        llm_cfg: LlmConfigDictInternal = llm_cfg_any if isinstance(llm_cfg_any, dict) else {}
        src_cfg: SourceConfigDictInternal = src_cfg_any if isinstance(src_cfg_any, dict) else {}

        footer_info = FooterInfo(
            provider_name=str(llm_cfg.get("provider", FOOTER_PROVIDER_DEFAULT)),
            model_name=str(llm_cfg.get("model", FOOTER_MODEL_DEFAULT)),
            is_local=bool(llm_cfg.get("is_local_llm", False)),
            source_language=str(src_cfg.get("language", FOOTER_SOURCE_LANG_DEFAULT)),
        )
        project_name_str = str(data.get("project_name", DEFAULT_PROJECT_NAME_COMBINE))
        safe_project_name = sanitize_filename(project_name_str, allow_underscores=False)
        if not safe_project_name or safe_project_name == ".":
            safe_project_name = DEFAULT_PROJECT_NAME_COMBINE
            self._log_warning("Project name sanitized to invalid. Using default: '%s'", safe_project_name)

        output_base_str = str(data.get("output_base_dir", DEFAULT_OUTPUT_DIR_COMBINE))
        output_path_obj = Path(output_base_str) / safe_project_name
        return data, footer_info, output_path_obj

    def pre_execution(self, shared_context: SLSharedContext) -> CombinePreparedInputs:
        """Prepare all tutorial content and write output files."""
        self._log_info(">>> CombineTutorial.pre_execution: Assembling and writing tutorial files. <<<")
        write_success = False
        output_path: Optional[Path] = None
        try:
            retrieved_data, footer_obj, output_path_obj = self._initialize_combine_data(shared_context)
            output_path = output_path_obj
            self._logger.debug("Initialized data for pre_execution. Output path: %s", output_path_obj)
            write_success = self._process_and_write_tutorial_files(
                shared_context, retrieved_data, footer_obj, output_path_obj
            )
            shared_context["final_output_dir"] = str(output_path_obj.resolve()) if write_success else None
            if not write_success:
                self._log_error("Pre-execution: File writing reported errors.")
        except ValueError as e_val:
            self._log_error("Pre-execution: Critical data missing or invalid: %s", e_val, exc_info=True)
            raise
        except OSError as e_os:
            self._log_error("Pre-execution: Critical filesystem error: %s", e_os, exc_info=True)
            raise LlmApiError(f"Combine failed: critical filesystem error: {e_os!s}") from e_os
        finally:
            if not write_success:
                log_msg_part1 = "Attempted to write to output directory: "
                log_msg_part2 = str(output_path.resolve()) if output_path else "N/A"
                self._log_warning(log_msg_part1 + log_msg_part2 + ". Check logs for specific file errors.")
        self._log_info(">>> CombineTutorial.pre_execution: Exit. Write successful: %s <<<", write_success)
        return write_success

    def execution(self, prepared_inputs: CombinePreparedInputs) -> CombineExecutionResult:
        """Execute step for CombineTutorial (no-op)."""
        self._log_info("CombineTutorial.execution: No direct action (pre_execution result: %s).", prepared_inputs)
        if not prepared_inputs:
            self._log_warning("Execution: pre_execution step indicated failure or no content was written.")
        return None

    def post_execution(
        self,
        shared_context: SLSharedContext,
        prepared_inputs: CombinePreparedInputs,
        execution_outputs: CombineExecutionResult,
    ) -> None:
        """Post-execution step for CombineTutorial."""
        del execution_outputs
        final_dir_val: Any = shared_context.get("final_output_dir")
        final_dir_str: str = str(final_dir_val) if final_dir_val else "Not set or N/A"
        status_msg: str
        if prepared_inputs and final_dir_val:
            status_msg = "successfully"
        elif prepared_inputs:
            status_msg = "completed (possibly no content to write, or output path issue)"
        else:
            status_msg = "with critical errors or no output generated"

        log_msg_l1 = f"CombineTutorial.post_execution: Processing finished {status_msg}. "
        log_msg_l2 = f"Final output dir: {final_dir_str}"
        self._log_info(log_msg_l1 + log_msg_l2)


# End of src/sourcelens/nodes/n10_combine_tutorial.py
