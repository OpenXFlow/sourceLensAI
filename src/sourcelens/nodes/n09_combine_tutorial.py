# Copyright (C) 2025 Jozef Darida (Find me on LinkedIn/Xing)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""Node responsible for combining generated tutorial components into final files."""

import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Final, Literal, Optional, Union, get_args

from typing_extensions import TypeAlias

from sourcelens.utils._exceptions import LlmApiError  # Specific error for LLM issues
from sourcelens.utils.helpers import sanitize_filename

from .base_node import BaseNode, SLSharedState

CombinePrepResult: TypeAlias = bool
CombineExecResult: TypeAlias = None

AbstractionItem: TypeAlias = dict[str, Any]
AbstractionsList: TypeAlias = list[AbstractionItem]

RelationshipDetail: TypeAlias = dict[str, Any]
RelationshipsDict: TypeAlias = dict[str, Union[str, list[RelationshipDetail]]]

ChapterOrderList: TypeAlias = list[int]
ChapterContentList: TypeAlias = list[str]
ChapterTypeLiteral: TypeAlias = Literal["standard", "diagrams", "source_index"]

ChapterFileData: TypeAlias = dict[str, Any]
AllChaptersDataList: TypeAlias = list[ChapterFileData]

DiagramMarkup: TypeAlias = Optional[str]
SequenceDiagramsList: TypeAlias = list[DiagramMarkup]
DiagramConfigDict: TypeAlias = dict[str, Any]
SequenceDiagramConfigDict: TypeAlias = dict[str, Any]
IdentifiedScenarioList: TypeAlias = list[str]

ConfigDict: TypeAlias = dict[str, Any]
LlmConfigDict: TypeAlias = dict[str, Any]
SourceConfigDict: TypeAlias = dict[str, Any]
OutputConfigDict: TypeAlias = dict[str, Any]

SharedDataForCombine: TypeAlias = dict[str, Any]


DIAGRAMS_CHAPTER_TITLE: Final[str] = "Architecture Diagrams"
DIAGRAMS_FILENAME_BASE: Final[str] = "diagrams"
SOURCE_INDEX_CHAPTER_TITLE: Final[str] = "Code Inventory"
SOURCE_INDEX_FILENAME_BASE: Final[str] = "code_inventory"
INDEX_FILENAME: Final[str] = "index.md"
FOOTER_SEPARATOR: Final[str] = "\n\n---\n\n*Generated by"
PREV_LINK_REGEX: Final[re.Pattern[str]] = re.compile(
    r"^\s*(?:> ?)?Previously, we looked at\s+\[.*?\]\(.*?\)\.?\s*$",
    re.IGNORECASE | re.MULTILINE,
)
NEXT_LINK_REGEX: Final[re.Pattern[str]] = re.compile(
    r"^\s*(?:> ?)?Next, we will examine\s+\[.*?\]\(.*?\)\.?\s*$",
    re.IGNORECASE | re.MULTILINE,
)
H1_HEADING_REGEX: Final[re.Pattern[str]] = re.compile(r"^\s*#\s+.*$", re.MULTILINE)

DEFAULT_PROJECT_NAME_COMBINE: Final[str] = "sourcelens_tutorial_output"
DEFAULT_OUTPUT_DIR_COMBINE: Final[str] = "output"
FOOTER_PROVIDER_DEFAULT: Final[str] = "N/A"
FOOTER_MODEL_DEFAULT: Final[str] = "N/A"
FOOTER_SOURCE_LANG_DEFAULT: Final[str] = "N/A"
FILENAME_CHAPTER_PREFIX_WIDTH_COMBINE: Final[int] = 2


@dataclass(frozen=True)
class FooterInfo:
    """Encapsulate information needed to generate the file footer."""

    provider_name: str
    model_name: str
    is_local: bool
    source_language: str

    def format_footer(self) -> str:
        """Generate the formatted footer string.

        Returns:
            A string representing the standard tutorial footer.
        """
        location: str = "(local)" if self.is_local else "(cloud)"
        repo_link: str = "https://github.com/darijo2yahoocom/sourceLensAI"
        part1: str = f"{FOOTER_SEPARATOR} [SourceLens AI]({repo_link}) "
        part2: str = f"using LLM: `{self.provider_name}` {location} "
        part3: str = f"- model: `{self.model_name}` | Language Profile: `{self.source_language}`*"
        return part1 + part2 + part3


@dataclass(frozen=True)
class IndexContext:
    """Encapsulate context needed to prepare the index.md file content."""

    project_name: str
    relationships_data: RelationshipsDict
    footer_info: FooterInfo
    repo_url: Optional[str] = None
    local_dir: Optional[str] = None
    relationship_flowchart_markup: DiagramMarkup = None
    chapter_files_data: AllChaptersDataList = field(default_factory=list)
    diagram_config: DiagramConfigDict = field(default_factory=dict)
    include_rel_flowchart: bool = field(init=False)

    def __post_init__(self) -> None:
        """Set derived diagram flags after initialization."""
        include_flag_val: Any = self.diagram_config.get("include_relationship_flowchart", False)
        include_flag: bool = include_flag_val if isinstance(include_flag_val, bool) else False
        object.__setattr__(self, "include_rel_flowchart", include_flag)


@dataclass
class DiagramMarkupContext:
    """Context for adding diagram markup to a content list."""

    content_parts: list[str]
    markup: DiagramMarkup
    diagram_title: str
    diagram_description: str
    diagram_format: str
    log_message: str


class CombineTutorial(BaseNode[CombinePrepResult, CombineExecResult]):
    """Combine generated tutorial components into final Markdown files."""

    def _add_diagram_markup(self, ctx: DiagramMarkupContext) -> bool:
        """Add a diagram's markup and description to content parts.

        Args:
            ctx: A `DiagramMarkupContext` object.

        Returns:
            True if the diagram markup was valid and added, False otherwise.
        """
        if ctx.markup and ctx.markup.strip():
            ctx.content_parts.append(f"## {ctx.diagram_title}\n")
            ctx.content_parts.append(f"{ctx.diagram_description}\n")
            ctx.content_parts.append(f"```{ctx.diagram_format}\n{ctx.markup.strip()}\n```\n")
            self._log_info(ctx.log_message)
            return True
        self._log_warning("Attempted to add diagram '%s', but markup was empty.", ctx.diagram_title)
        return False

    def _add_sequence_diagrams_markup(
        self,
        content_parts: list[str],
        seq_diag_markups: SequenceDiagramsList,
        identified_scenarios: IdentifiedScenarioList,
        diagram_format: str,
    ) -> bool:
        """Add multiple sequence diagrams with descriptions to content parts list.

        Args:
            content_parts: The list of string parts to append to.
            seq_diag_markups: A list of Mermaid markup strings for sequence diagrams.
            identified_scenarios: A list of scenario descriptions.
            diagram_format: The format of the diagrams (e.g., "mermaid").

        Returns:
            True if at least one valid sequence diagram was added, False otherwise.
        """
        valid_markups_with_scenarios: list[tuple[str, str]] = []
        for i, markup_item in enumerate(seq_diag_markups):
            if markup_item and markup_item.strip():
                scenario_desc = f"Scenario {i + 1}"
                if i < len(identified_scenarios) and identified_scenarios[i] and identified_scenarios[i].strip():
                    scenario_desc = identified_scenarios[i]
                valid_markups_with_scenarios.append((scenario_desc, markup_item.strip()))

        if not valid_markups_with_scenarios:
            self._log_warning("No valid sequence diagram markups to add.")
            return False

        if not any("## Sequence Diagrams" in part for part in content_parts if part.startswith("## ")):
            content_parts.append("## Sequence Diagrams\n")
            content_parts.append(
                "These diagrams illustrate various interaction scenarios within the application, "
                "showcasing the sequence of operations between different components for specific use cases.\n"
            )

        for scenario_desc, seq_markup in valid_markups_with_scenarios:
            content_parts.append(f"### {scenario_desc}\n")
            content_parts.append(f"```{diagram_format}\n{seq_markup}\n```\n")

        self._log_info("Adding %d Sequence Diagram(s) markup.", len(valid_markups_with_scenarios))
        return True

    def _add_prev_link(self, chapter_data: ChapterFileData, prev_link_text: Optional[str]) -> None:
        """Ensure the 'Previously...' navigation link exists once before H1 heading.

        Args:
            chapter_data: The dictionary for the current chapter.
            prev_link_text: The Markdown formatted string for the previous link, or None.
        """
        if not prev_link_text or not prev_link_text.strip():
            return
        content: str = str(chapter_data.get("content", "") or "")
        chapter_num_str = str(chapter_data.get("num", "Unknown"))

        content, num_removed = PREV_LINK_REGEX.subn("", content)
        if num_removed > 0:
            self._log_info("Removed %d existing 'Previously...' link(s) from chapter %s.", num_removed, chapter_num_str)
        content = re.sub(r"^\s*\n", "", content, flags=re.MULTILINE)
        content = re.sub(r"\n{3,}", "\n\n", content).strip()

        h1_match = H1_HEADING_REGEX.search(content)
        if h1_match:
            start_index = h1_match.start()
            prefix_newline = "\n" if start_index > 0 and not content[:start_index].isspace() else ""
            content_before_h1 = content[:start_index].rstrip()
            content_after_h1 = content[start_index:]
            content = f"{content_before_h1}{prefix_newline}\n\n{prev_link_text}\n\n{content_after_h1}"
            self._log_info("Ensured 'Previously...' link exists before H1 in chapter %s.", chapter_num_str)
        else:
            content = f"{prev_link_text}\n\n{content}"
            self._log_warning("No H1 in chapter %s. Added 'Previously...' link at start.", chapter_num_str)
        chapter_data["content"] = content.strip()

    def _add_next_link(self, chapter_data: ChapterFileData, next_link_text: Optional[str]) -> None:
        """Ensure the 'Next...' navigation link exists once at the end of chapter content.

        Args:
            chapter_data: The dictionary for the current chapter.
            next_link_text: The Markdown formatted string for the next link, or None.
        """
        if not next_link_text or not next_link_text.strip():
            return
        content: str = str(chapter_data.get("content", "") or "")
        chapter_num_str = str(chapter_data.get("num", "Unknown"))

        content, num_removed = NEXT_LINK_REGEX.subn("", content)
        if num_removed > 0:
            self._log_info("Removed %d existing 'Next...' link(s) from chapter %s.", num_removed, chapter_num_str)
        content = re.sub(r"\n{3,}", "\n\n", content).strip()
        content += f"\n\n{next_link_text}" if content else next_link_text
        chapter_data["content"] = content.strip()
        self._log_info("Ensured 'Next...' link exists in chapter %s.", chapter_num_str)

    def _add_navigation_links(self, all_chapters_data: AllChaptersDataList, index_filename: str) -> None:
        """Add or update 'Previously...' and 'Next...' links in all chapters.

        Args:
            all_chapters_data: A list of chapter data dictionaries to be modified.
            index_filename: The filename of the main index/overview page.
        """
        num_all_chapters = len(all_chapters_data)
        if num_all_chapters == 0:
            self._log_warning("No chapters found to add navigation links.")
            return

        for i, chapter_data in enumerate(all_chapters_data):
            prev_link_text: Optional[str] = None
            if i == 0:
                prev_link_text = f"Previously, we looked at the [Project Overview]({index_filename})."
            elif (
                i > 0
                and (prev_name_any := all_chapters_data[i - 1].get("name"))
                and isinstance(prev_name_any, str)
                and prev_name_any.strip()
                and (prev_file_any := all_chapters_data[i - 1].get("filename"))
                and isinstance(prev_file_any, str)
                and prev_file_any.strip()
            ):
                prev_name: str = prev_name_any
                prev_file: str = prev_file_any
                prev_link_text = f"Previously, we looked at [{prev_name}]({prev_file})."
            else:
                self._log_warning("Could not create 'previous' link for chapter %s.", chapter_data.get("num", i + 1))
            self._add_prev_link(chapter_data, prev_link_text)

            next_link_text: Optional[str] = None
            if i < num_all_chapters - 1:
                next_ch_data = all_chapters_data[i + 1]
                next_name_any, next_file_any = next_ch_data.get("name"), next_ch_data.get("filename")
                if (
                    isinstance(next_name_any, str)
                    and next_name_any.strip()
                    and isinstance(next_file_any, str)
                    and next_file_any.strip()
                ):
                    next_name: str = next_name_any
                    next_file: str = next_file_any
                    next_link_text = f"Next, we will examine [{next_name.strip()}]({next_file.strip()})."
                else:
                    self._log_warning("Could not create 'next' link for chapter %s.", chapter_data.get("num", i + 1))
            self._add_next_link(chapter_data, next_link_text)

    def _add_footers(self, all_chapters_data: AllChaptersDataList, footer_text: str) -> None:
        """Append the standard footer to all chapter contents.

        Args:
            all_chapters_data: A list of chapter data dictionaries to be modified.
            footer_text: The footer string to append.
        """
        clean_footer_text: str = footer_text.strip()
        if not clean_footer_text:
            self._log_warning("Footer text is empty, not adding footers.")
            return
        for chapter_data in all_chapters_data:
            current_content: str = str(chapter_data.get("content", "") or "")
            if FOOTER_SEPARATOR in current_content:
                current_content = current_content.split(FOOTER_SEPARATOR, 1)[0]
            current_content = current_content.rstrip()
            current_content += f"\n{footer_text}" if current_content else footer_text.lstrip()
            chapter_data["content"] = current_content

    def _prepare_index_header(self, context: IndexContext) -> list[str]:
        """Prepare the header section of the index.md.

        Args:
            context: An `IndexContext` object containing project and relationship data.

        Returns:
            A list of strings forming the index header.
        """
        summary_raw: Any = context.relationships_data.get("summary", f"Tutorial for {context.project_name}.")
        summary: str = str(summary_raw or f"Tutorial for {context.project_name}.")
        header_parts: list[str] = [f"# Tutorial: {context.project_name}\n\n{summary}\n"]
        source_info: str = ""
        if context.repo_url:
            source_info = f"**Source Repository:** [{context.repo_url}]({context.repo_url})"
        elif context.local_dir:
            try:
                resolved_local_dir = Path(str(context.local_dir)).resolve(strict=False)
                source_info = f"**Source Directory:** `{resolved_local_dir}`"
            except (OSError, TypeError, ValueError) as e:  # Catch specific errors related to path operations
                self._log_warning("Cannot resolve local_dir '%s': %s", context.local_dir, e)
                source_info = f"**Source Directory:** `{str(context.local_dir)}` (resolution failed)"
        if source_info:
            header_parts.append(f"{source_info}\n")
        return header_parts

    def _prepare_index_diagram(self, context: IndexContext) -> list[str]:
        """Prepare the relationship diagram section of the index.md.

        Args:
            context: An `IndexContext` object containing diagram configuration and markup.

        Returns:
            A list of strings for the diagram section, or an empty list if not applicable.
        """
        diagram_parts: list[str] = []
        diagram_format = str(context.diagram_config.get("format", "mermaid"))
        if context.include_rel_flowchart and context.relationship_flowchart_markup:
            markup = str(context.relationship_flowchart_markup).strip()
            if markup:
                diagram_parts.extend(["## Abstraction Relationships\n", f"```{diagram_format}\n{markup}\n```\n"])
                self._log_info("Embedding relationship flowchart into index.md.")
            else:
                self._log_warning("Rel flowchart enabled for index.md, but markup was empty.")
        elif context.include_rel_flowchart:
            self._log_warning("Rel flowchart enabled for index.md, but no markup provided.")
        return diagram_parts

    def _prepare_index_chapters(self, context: IndexContext) -> list[str]:
        """Prepare the chapters listing section of the index.md.

        Args:
            context: An `IndexContext` object containing chapter file data.

        Returns:
            A list of strings for the chapter listing.
        """
        chapter_parts: list[str] = ["## Chapters\n"]
        sorted_chapters: AllChaptersDataList = context.chapter_files_data
        try:
            sorted_chapters = sorted(
                context.chapter_files_data,
                key=lambda x: (
                    x.get("num", float("inf")) if isinstance(x.get("num"), int) else float("inf"),
                    str(x.get("name", "")),
                ),
            )
        except (TypeError, ValueError) as e_sort:
            self._log_warning("Cannot sort chapters by 'num'; using original order. Error: %s", e_sort)
            sorted_chapters = context.chapter_files_data

        chapter_links: list[str] = []
        for ch_data in sorted_chapters:
            num_val, name_val, fname_val = (ch_data.get("num"), ch_data.get("name"), ch_data.get("filename"))
            if (
                isinstance(num_val, int)
                and num_val > 0
                and isinstance(name_val, str)
                and name_val.strip()
                and isinstance(fname_val, str)
                and fname_val.strip()
            ):
                chapter_links.append(f"{num_val}. [{name_val.strip()}]({fname_val.strip()})")
            else:
                self._log_warning("Skipping chapter link in index.md due to invalid data: %s", ch_data)
        chapter_parts.append("\n".join(chapter_links) if chapter_links else "No chapters available.")
        return chapter_parts

    def _prepare_index_content(self, context: IndexContext) -> str:
        """Prepare the full Markdown content for the index.md file.

        Args:
            context: An `IndexContext` object containing all necessary data.

        Returns:
            A string with the complete Markdown content for `index.md`.
        """
        self._log_info("Preparing index.md content for project '%s'...", context.project_name)
        content_parts: list[str] = []
        content_parts.extend(self._prepare_index_header(context))
        content_parts.extend(self._prepare_index_diagram(context))
        content_parts.extend(self._prepare_index_chapters(context))
        return "\n".join(content_parts)

    def _prepare_standard_chapters_data(
        self,
        abstractions: AbstractionsList,
        chapter_order: ChapterOrderList,
        chapters_content: ChapterContentList,
    ) -> AllChaptersDataList:
        """Prepare initial data structure for standard chapter files.

        Args:
            abstractions: The list of all identified abstractions.
            chapter_order: Ordered list of abstraction indices for chapters.
            chapters_content: List of Markdown content for chapters.

        Returns:
            A list of `ChapterFileData` dictionaries for standard chapters.
        """
        standard_chapters_data: AllChaptersDataList = []
        num_abstractions = len(abstractions)
        effective_count = min(len(chapter_order), len(chapters_content))
        if len(chapter_order) != len(chapters_content):
            self._log_warning(
                "Chapter order count (%d) != content count (%d). Processing %d.",
                len(chapter_order),
                len(chapters_content),
                effective_count,
            )
        for i in range(effective_count):
            abs_idx = chapter_order[i]
            if not (0 <= abs_idx < num_abstractions):
                self._log_warning("Invalid abs_idx %d at order pos %d. Skipping.", abs_idx, i)
                continue
            abs_item: AbstractionItem = abstractions[abs_idx]
            name_raw: Any = abs_item.get("name", f"Concept {i + 1}")
            name: str = str(name_raw).strip() if isinstance(name_raw, str) and name_raw.strip() else f"Concept {i + 1}"
            chapter_file_data: ChapterFileData = {
                "filename": "",
                "content": str(chapters_content[i] or ""),
                "name": name,
                "abstraction_index": abs_idx,
                "num": -1,
                "chapter_type": "standard",
            }
            standard_chapters_data.append(chapter_file_data)
        self._log_info("Prepared data for %d standard chapters.", len(standard_chapters_data))
        return standard_chapters_data

    def _prepare_diagrams_chapter_data(
        self, shared: SLSharedState, diagram_config: DiagramConfigDict
    ) -> Optional[ChapterFileData]:
        """Prepare data for the dedicated diagrams chapter.

        Args:
            shared: The shared state dictionary.
            diagram_config: The 'diagram_generation' section of the config.

        Returns:
            A `ChapterFileData` dictionary or None if no diagrams are to be included.
        """
        content_parts: list[str] = [f"# {DIAGRAMS_CHAPTER_TITLE}\n"]
        fmt = str(diagram_config.get("format", "mermaid"))
        proj_any: Any = shared.get("project_name", DEFAULT_PROJECT_NAME_COMBINE)
        proj: str = str(proj_any)
        has_content = False

        if bool(diagram_config.get("include_class_diagram", False)):
            markup_val: Any = shared.get("class_diagram_markup")
            class_diag_markup: DiagramMarkup = str(markup_val) if isinstance(markup_val, str) else None
            if self._add_diagram_markup(
                DiagramMarkupContext(
                    content_parts,
                    class_diag_markup,
                    "Class Diagram",
                    f"Key classes in **{proj}**, attributes, methods, relationships.",
                    fmt,
                    "Adding Class Diagram.",
                )
            ):
                has_content = True
        if bool(diagram_config.get("include_package_diagram", False)):
            markup_val_pkg: Any = shared.get("package_diagram_markup")
            pkg_diag_markup: DiagramMarkup = str(markup_val_pkg) if isinstance(markup_val_pkg, str) else None
            if self._add_diagram_markup(
                DiagramMarkupContext(
                    content_parts,
                    pkg_diag_markup,
                    "Package Dependencies",
                    f"High-level modular structure of **{proj}** and dependencies.",
                    fmt,
                    "Adding Package Diagram.",
                )
            ):
                has_content = True

        seq_cfg_raw: Any = diagram_config.get("include_sequence_diagrams", {})
        seq_cfg: SequenceDiagramConfigDict = seq_cfg_raw if isinstance(seq_cfg_raw, dict) else {}
        if bool(seq_cfg.get("enabled", False)):
            markups_raw: Any = shared.get("sequence_diagrams_markup", [])
            scenarios_raw: Any = shared.get("identified_scenarios", [])
            markups: SequenceDiagramsList = (
                [str(m) if isinstance(m, str) else None for m in markups_raw] if isinstance(markups_raw, list) else []
            )
            scenarios: IdentifiedScenarioList = (
                [str(s) for s in scenarios_raw if isinstance(s, str) and s.strip()]
                if isinstance(scenarios_raw, list)
                else []
            )
            if self._add_sequence_diagrams_markup(content_parts, markups, scenarios, fmt):
                has_content = True

        if has_content:
            diagram_chapter_data: ChapterFileData = {
                "filename": "",
                "content": "\n".join(content_parts),
                "name": DIAGRAMS_CHAPTER_TITLE,
                "num": -1,
                "abstraction_index": -1,
                "chapter_type": "diagrams",
            }
            return diagram_chapter_data
        return None

    def _prepare_source_index_chapter_data(self, shared: SLSharedState) -> Optional[ChapterFileData]:
        """Prepare data for the source index chapter.

        Args:
            shared: The shared state dictionary.

        Returns:
            A `ChapterFileData` dictionary or None if no content.
        """
        content_val: Any = shared.get("source_index_content")
        if not (isinstance(content_val, str) and content_val.strip()):
            self._log_info("No valid source index content for chapter.")
            return None
        self._log_info("Source index chapter data prepared (len: %d).", len(content_val))
        src_idx_chapter_data: ChapterFileData = {
            "filename": "",
            "content": content_val,
            "name": SOURCE_INDEX_CHAPTER_TITLE,
            "num": -1,
            "abstraction_index": -2,
            "chapter_type": "source_index",
        }
        return src_idx_chapter_data

    def _assemble_chapters(self, shared: SLSharedState, data: SharedDataForCombine) -> AllChaptersDataList:
        """Assemble all chapter types and assign numbers/filenames.

        Args:
            shared: The shared state dictionary.
            data: The `SharedDataForCombine` dictionary.

        Returns:
            A list of all prepared `ChapterFileData` dictionaries.
        """
        self._log_info("Assembling all chapter data...")
        cfg_any: Any = data.get("config", {})
        cfg: ConfigDict = cfg_any if isinstance(cfg_any, dict) else {}
        out_cfg_any: Any = cfg.get("output", {})
        out_cfg: OutputConfigDict = out_cfg_any if isinstance(out_cfg_any, dict) else {}

        inc_src_idx_raw: Any = out_cfg.get("include_source_index")
        inc_src_idx: bool = inc_src_idx_raw if isinstance(inc_src_idx_raw, bool) else False

        abstractions_any: Any = data.get("abstractions", [])
        chapter_order_any: Any = data.get("chapter_order", [])
        chapters_content_any: Any = data.get("chapters_content", [])

        abstractions: AbstractionsList = abstractions_any if isinstance(abstractions_any, list) else []
        chapter_order: ChapterOrderList = chapter_order_any if isinstance(chapter_order_any, list) else []
        chapters_content: ChapterContentList = chapters_content_any if isinstance(chapters_content_any, list) else []

        std_chapters: AllChaptersDataList = self._prepare_standard_chapters_data(
            abstractions, chapter_order, chapters_content
        )
        diag_cfg_any: Any = out_cfg.get("diagram_generation", {})
        diag_cfg: DiagramConfigDict = diag_cfg_any if isinstance(diag_cfg_any, dict) else {}
        diag_chapter: Optional[ChapterFileData] = self._prepare_diagrams_chapter_data(shared, diag_cfg)
        src_idx_chapter: Optional[ChapterFileData] = (
            self._prepare_source_index_chapter_data(shared) if inc_src_idx else None
        )

        all_chapters: AllChaptersDataList = list(std_chapters)
        if diag_chapter:
            all_chapters.append(diag_chapter)
        if src_idx_chapter:
            all_chapters.append(src_idx_chapter)

        for i, chapter_info in enumerate(all_chapters):
            chapter_info["num"] = i + 1
            ch_type_val_any: Any = chapter_info.get("chapter_type", "standard")
            ch_type: ChapterTypeLiteral = "standard"
            if ch_type_val_any in get_args(ChapterTypeLiteral):
                ch_type = ch_type_val_any  # type: ignore[assignment]
            else:
                self._log_warning("Unexpected chapter_type '%s'. Defaulting.", ch_type_val_any)

            base_name_def = f"chapter-{i + 1}"
            name_raw_val_any: Any = chapter_info.get("name", base_name_def)
            name_raw_val: str = str(name_raw_val_any)

            name_base: str
            if ch_type == "diagrams":
                name_base = DIAGRAMS_FILENAME_BASE
            elif ch_type == "source_index":
                name_base = SOURCE_INDEX_FILENAME_BASE
            else:
                name_base = sanitize_filename(name_raw_val) or base_name_def

            chapter_info["filename"] = f"{i + 1:0{FILENAME_CHAPTER_PREFIX_WIDTH_COMBINE}d}_{name_base}.md"
        self._log_info("Assembled %d chapters.", len(all_chapters))
        return all_chapters

    def _process_and_write_tutorial_files(
        self,
        shared: SLSharedState,
        data: SharedDataForCombine,
        footer_info: FooterInfo,
        output_path_obj: Path,
    ) -> bool:
        """Orchestrate chapter assembly, formatting, and file writing.

        Args:
            shared: The shared state dictionary.
            data: The `SharedDataForCombine` dictionary.
            footer_info: The `FooterInfo` object.
            output_path_obj: The root output `Path` for the tutorial.

        Returns:
            True if file writing was broadly successful, False otherwise.
        """
        markup_raw: Any = data.get("rel_flowchart_markup")
        rel_flow_markup: DiagramMarkup = str(markup_raw) if isinstance(markup_raw, str) else None
        all_chapters: AllChaptersDataList = self._assemble_chapters(shared, data)
        if not all_chapters and not (rel_flow_markup and rel_flow_markup.strip()):
            self._log_warning("No content to combine. Skipping file writes.")
            shared["final_output_dir"] = str(output_path_obj.resolve())
            return True

        footer_str: str = footer_info.format_footer()
        self._add_navigation_links(all_chapters, INDEX_FILENAME)
        self._add_footers(all_chapters, footer_str)

        cfg_any: Any = data.get("config", {})
        cfg: ConfigDict = cfg_any if isinstance(cfg_any, dict) else {}
        out_cfg_any: Any = cfg.get("output", {})
        out_cfg: OutputConfigDict = out_cfg_any if isinstance(out_cfg_any, dict) else {}
        diag_cfg_any: Any = out_cfg.get("diagram_generation", {})
        diag_cfg: DiagramConfigDict = diag_cfg_any if isinstance(diag_cfg_any, dict) else {}

        project_name_any: Any = data.get("project_name", DEFAULT_PROJECT_NAME_COMBINE)
        relationships_data_any: Any = data.get("relationships_data", {})
        repo_url_any: Any = data.get("repo_url")
        local_dir_any: Any = data.get("local_dir")

        idx_ctx = IndexContext(
            project_name=str(project_name_any),
            relationships_data=relationships_data_any if isinstance(relationships_data_any, dict) else {},  # type: ignore[arg-type]
            footer_info=footer_info,
            repo_url=str(repo_url_any) if isinstance(repo_url_any, str) else None,
            local_dir=str(local_dir_any) if isinstance(local_dir_any, str) else None,
            relationship_flowchart_markup=rel_flow_markup,
            chapter_files_data=all_chapters,
            diagram_config=diag_cfg,
        )
        index_md_content: str = self._prepare_index_content(idx_ctx)
        if FOOTER_SEPARATOR not in index_md_content:
            index_md_content = index_md_content.rstrip() + f"\n{footer_str}"
        return self._write_output_files(output_path_obj, index_md_content, all_chapters)

    def _write_output_files(
        self, output_path: Path, index_content: str, all_chapter_files_data: AllChaptersDataList
    ) -> bool:
        """Write the index.md and all generated chapter files to disk.

        Args:
            output_path: The base `Path` object for the output directory.
            index_content: The complete Markdown content for `index.md`.
            all_chapter_files_data: A list of chapter data dictionaries.

        Returns:
            True if all files were written successfully, False if any OS error occurred.

        Raises:
            OSError: If the output directory cannot be created.
        """
        try:
            output_path.mkdir(parents=True, exist_ok=True)
            self._log_info("Ensured output directory exists: %s", output_path.resolve())
        except OSError as e_dir:
            self._log_error("CRITICAL: Failed to create output directory %s: %s", output_path, e_dir, exc_info=True)
            raise

        index_filepath = output_path / INDEX_FILENAME
        try:
            index_filepath.write_text(index_content, encoding="utf-8")
            self._log_info("Wrote index file: %s", index_filepath)
        except OSError as e_idx:
            self._log_error("CRITICAL: Failed to write index file %s: %s", index_filepath, e_idx, exc_info=True)
            return False

        all_writes_ok = True
        self._log_info("Attempting to write %d chapter files.", len(all_chapter_files_data))
        for ch_info in all_chapter_files_data:
            fname_val_any, content_val_any, ch_name_val_any = (
                ch_info.get("filename"),
                ch_info.get("content"),
                ch_info.get("name", "Unknown Chapter"),
            )
            fname_val: Optional[str] = str(fname_val_any) if isinstance(fname_val_any, str) else None
            content_val: Optional[str] = str(content_val_any) if isinstance(content_val_any, str) else None
            ch_name_val: str = str(ch_name_val_any)

            if not (fname_val and fname_val.strip() and content_val is not None):
                self._log_warning(
                    "Skipping file write for chapter '%s': invalid filename or missing content.", ch_name_val
                )
                all_writes_ok = False
                continue
            ch_filepath = output_path / fname_val
            try:
                ch_filepath.write_text(content_val, encoding="utf-8")
                self._log_info("Wrote chapter file: %s (Name: '%s')", ch_filepath, ch_name_val)
            except OSError as e_ch:
                self._log_error(
                    "Failed to write chapter file %s (Name: '%s'): %s", ch_filepath, ch_name_val, e_ch, exc_info=True
                )
                all_writes_ok = False
        if not all_writes_ok:
            self._log_warning("One or more chapter file writes failed. Please check logs.")
        return all_writes_ok

    def _retrieve_shared_data(self, shared: SLSharedState) -> SharedDataForCombine:
        """Retrieve all necessary data from shared state for combination logic.

        Args:
            shared: The shared state dictionary from the workflow.

        Returns:
            A dictionary (`SharedDataForCombine`) containing all retrieved data.

        Raises:
            ValueError: If any of the required keys are missing from `shared_state`.
        """
        data: SharedDataForCombine = {
            "project_name": str(self._get_required_shared(shared, "project_name")),
            "output_base_dir": str(self._get_required_shared(shared, "output_dir")),
            "relationships_data": self._get_required_shared(shared, "relationships"),  # type: ignore[assignment]
            "chapter_order": self._get_required_shared(shared, "chapter_order"),  # type: ignore[assignment]
            "abstractions": self._get_required_shared(shared, "abstractions"),  # type: ignore[assignment]
            "chapters_content": self._get_required_shared(shared, "chapters"),  # type: ignore[assignment]
            "llm_config": self._get_required_shared(shared, "llm_config"),  # type: ignore[assignment]
            "source_config": self._get_required_shared(shared, "source_config"),  # type: ignore[assignment]
            "config": self._get_required_shared(shared, "config"),  # type: ignore[assignment]
            "repo_url": shared.get("repo_url"),
            "local_dir": shared.get("local_dir"),
            "relationship_flowchart_markup": shared.get("relationship_flowchart_markup"),
            "class_diagram_markup": shared.get("class_diagram_markup"),
            "package_diagram_markup": shared.get("package_diagram_markup"),
            "sequence_diagrams_markup": shared.get("sequence_diagrams_markup", []),
            "identified_scenarios": shared.get("identified_scenarios", []),
            "source_index_content": shared.get("source_index_content"),
        }
        return data

    def _initialize_combine_data(self, shared: SLSharedState) -> tuple[SharedDataForCombine, FooterInfo, Path]:
        """Initialize data structures needed for combining the tutorial.

        Args:
            shared: The shared state dictionary.

        Returns:
            A tuple containing retrieved shared data, footer info, and output path.
        """
        data: SharedDataForCombine = self._retrieve_shared_data(shared)
        llm_cfg_any: Any = data.get("llm_config", {})
        llm_cfg: LlmConfigDict = llm_cfg_any if isinstance(llm_cfg_any, dict) else {}
        src_cfg_any: Any = data.get("source_config", {})
        src_cfg: SourceConfigDict = src_cfg_any if isinstance(src_cfg_any, dict) else {}

        footer_info = FooterInfo(
            provider_name=str(llm_cfg.get("provider", FOOTER_PROVIDER_DEFAULT)),
            model_name=str(llm_cfg.get("model", FOOTER_MODEL_DEFAULT)),
            is_local=bool(llm_cfg.get("is_local_llm", False)),
            source_language=str(src_cfg.get("language", FOOTER_SOURCE_LANG_DEFAULT)),
        )
        project_name_str: str = str(data.get("project_name", DEFAULT_PROJECT_NAME_COMBINE))
        safe_project_name = sanitize_filename(project_name_str, allow_underscores=False)
        if not safe_project_name or safe_project_name == ".":
            safe_project_name = DEFAULT_PROJECT_NAME_COMBINE
            self._log_warning("Project name sanitized to invalid. Using default: '%s'", safe_project_name)
        output_base_str: str = str(data.get("output_base_dir", DEFAULT_OUTPUT_DIR_COMBINE))
        output_path_obj = Path(output_base_str) / safe_project_name
        return data, footer_info, output_path_obj

    def prep(self, shared: SLSharedState) -> CombinePrepResult:
        """Prepare all tutorial content and write output files.

        Args:
            shared: The shared state dictionary.

        Returns:
            True if file writing was broadly successful, False otherwise.

        Raises:
            LlmApiError: Re-wraps critical OS or unexpected errors.
            ValueError: If essential data is missing from `shared_state`.
        """
        self._log_info(">>> CombineTutorial.prep: Assembling and writing tutorial files. <<<")
        write_success: bool = False
        output_path: Optional[Path] = None
        try:
            retrieved_data, footer_obj, output_path_obj = self._initialize_combine_data(shared)
            output_path = output_path_obj
            write_success = self._process_and_write_tutorial_files(shared, retrieved_data, footer_obj, output_path_obj)
            if write_success:
                shared["final_output_dir"] = str(output_path_obj.resolve())
            else:
                self._log_error("Prep: File writing reported errors. 'final_output_dir' may not be set correctly.")
                shared["final_output_dir"] = None
        except ValueError as e_val:  # Catch ValueError from _get_required_shared or other logic
            self._log_error("Prep: Critical data missing or invalid: %s", e_val, exc_info=True)
            shared["final_output_dir"] = None
            raise  # Re-raise to be handled by flow engine
        except OSError as e_os:  # From file operations like mkdir, write_text
            self._log_error("Prep: Critical filesystem error: %s", e_os, exc_info=True)
            shared["final_output_dir"] = None
            raise LlmApiError(f"Combine failed: critical filesystem error: {e_os!s}") from e_os
        except (RuntimeError, TypeError) as e_runtime:  # Catch other specific runtime issues
            # This is more specific than a blanket Exception.
            self._log_error("Prep: Unexpected runtime error: %s", e_runtime, exc_info=True)
            shared["final_output_dir"] = None
            raise LlmApiError(f"Combine failed unexpectedly (runtime): {e_runtime!s}") from e_runtime
        # No broad `except Exception` to allow other unexpected errors to propagate for debugging.
        finally:
            if not write_success and output_path:
                self._log_warning(
                    "Attempted to write to output directory: %s. Check logs for specific file errors.",
                    output_path.resolve() if output_path else "N/A",
                )
            elif not write_success:
                self._log_warning("File writing failed and output path was not determined.")

        self._log_info(">>> CombineTutorial.prep: Exit. Write successful: %s <<<", write_success)
        return write_success

    def exec(self, prep_res: CombinePrepResult) -> CombineExecResult:
        """Execute step for CombineTutorial (no-op).

        Args:
            prep_res: The boolean result from the `prep` method.

        Returns:
            None.
        """
        self._log_info("CombineTutorial.exec: No direct action (prep result: %s).", prep_res)
        if not prep_res:
            self._log_warning("Exec: Prep step indicated failure or no content was written.")
        return None

    def post(self, shared: SLSharedState, prep_res: CombinePrepResult, exec_res: CombineExecResult) -> None:
        """Post-execution step for CombineTutorial.

        Args:
            shared: The shared state dictionary.
            prep_res: The result from the `prep` method.
            exec_res: The result from the `exec` method (None).
        """
        del exec_res
        final_dir_val: Any = shared.get("final_output_dir")
        final_dir_str: str = str(final_dir_val) if final_dir_val else "Not set or N/A"
        status_msg: str
        if prep_res and final_dir_val:
            status_msg = "successfully"
        elif prep_res:
            status_msg = "completed (possibly no content, or output path issue)"
        else:
            status_msg = "with critical errors or no output generated"

        self._log_info("CombineTutorial.post: Processing finished %s. Final output dir: %s", status_msg, final_dir_str)


# End of src/sourcelens/nodes/n09_combine_tutorial.py
