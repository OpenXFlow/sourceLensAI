# Copyright (C) 2025 Jozef Darida (LinkedIn/Xing)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""Node responsible for generating an AI-powered review of crawled web content."""

import logging
from typing import TYPE_CHECKING, Any, Final, Optional, cast

from typing_extensions import TypeAlias

from sourcelens.core import BaseNode, SLSharedContext
from sourcelens.utils.llm_api import LlmApiError, call_llm
from sourcelens.utils.validation import ValidationFailure, validate_yaml_dict

if TYPE_CHECKING:
    from sourcelens.core.common_types import (
        CacheConfigDict,
        LlmConfigDict,
        WebContentConceptsList,
        WebContentRelationshipsDict,
    )

from ..prompts.review_prompts import WEB_REVIEW_SCHEMA, WebReviewPrompts

WebReviewPreparedInputs: TypeAlias = dict[str, Any]
WebReviewExecutionResult: TypeAlias = Optional[str]  # Markdown content or error string

module_logger_web_review: logging.Logger = logging.getLogger(__name__)

MAX_REVIEW_SNIPPET_LEN_LOG: Final[int] = 200
ERROR_REVIEW_PREFIX: Final[str] = "Error generating web content review:"


class GenerateWebReview(BaseNode[WebReviewPreparedInputs, WebReviewExecutionResult]):
    """Generate an AI-powered review of analyzed web content."""

    def _format_review_yaml_to_markdown(self, review_data: dict[str, Any], collection_name: str) -> str:
        """Format the structured YAML data from LLM into Markdown.

        Args:
            review_data (dict[str, Any]): The validated dictionary parsed from LLM's YAML response.
            collection_name (str): The name of the document collection (e.g., website name).

        Returns:
            str: A string containing the formatted Markdown for the web content review.
        """
        markdown_parts: list[str] = [f"# Web Content Review: {collection_name}\n"]
        warning_text_l1: str = (
            "> **Note:** This review is automatically generated by an AI (Large Language Model) "
            "based on an analysis of the web content's identified concepts, "
        )
        warning_text_l2: str = (
            "relationships, and inventory. "
            "It is intended to provide high-level insights and stimulate discussion, "
            "not as a definitive expert assessment. "
            "Always use critical judgment when interpreting AI-generated content."
        )
        markdown_parts.append(f"{warning_text_l1}{warning_text_l2}\n")

        summary_val: Any = review_data.get("overall_assessment", "No overall assessment provided.")
        summary: str = str(summary_val)
        markdown_parts.append(f"## AI-Generated Overall Assessment\n\n{summary}\n")

        key_insights_any: Any = review_data.get("key_insights", [])
        key_insights: list[str] = (
            [str(i) for i in key_insights_any if isinstance(i, str)] if isinstance(key_insights_any, list) else []
        )
        if key_insights:
            markdown_parts.append("## Key Insights (AI-Observed)\n")
            for insight_item in key_insights:
                markdown_parts.append(f"- {insight_item}")
            markdown_parts.append("\n")

        areas_improve_any: Any = review_data.get("areas_for_improvement_or_clarification", [])
        areas_improve: list[str] = (
            [str(i) for i in areas_improve_any if isinstance(i, str)] if isinstance(areas_improve_any, list) else []
        )
        if areas_improve:
            markdown_parts.append("## Potential Areas for Improvement/Clarification (AI-Suggested)\n")
            for area_item in areas_improve:
                markdown_parts.append(f"- {area_item}")
            markdown_parts.append("\n")

        content_struct_any: Any = review_data.get("content_structure_observations", [])
        content_struct: list[str] = (
            [str(i) for i in content_struct_any if isinstance(i, str)] if isinstance(content_struct_any, list) else []
        )
        if content_struct:
            markdown_parts.append("## Content Structure Observations (AI-Noted)\n")
            for obs_item in content_struct:
                markdown_parts.append(f"- {obs_item}")
            markdown_parts.append("\n")
        return "\n".join(markdown_parts)

    def pre_execution(self, shared_context: SLSharedContext) -> WebReviewPreparedInputs:
        """Prepare necessary data and context for generating the web content review.

        Args:
            shared_context (SLSharedContext): The shared context dictionary.

        Returns:
            WebReviewPreparedInputs: Dictionary for `execution`, or {'skip': True}.
        """
        self._log_info("Preparing for web content review generation.")
        try:
            config_data: dict[str, Any] = cast(dict[str, Any], self._get_required_shared(shared_context, "config"))
            flow_name: str = str(shared_context.get("current_operation_mode", "FL02_web_crawling"))
            flow_config: dict[str, Any] = config_data.get(flow_name, {})
            current_mode_opts: dict[str, Any] = flow_config.get("output_options", {})

            include_review_val: Any = current_mode_opts.get("include_content_review")
            include_review: bool = bool(include_review_val) if isinstance(include_review_val, bool) else True

            if not include_review:
                self._log_info("Web content review is disabled in output_options. Skipping.")
                return {"skip": True, "reason": "Disabled via 'output_options.include_content_review'"}

            concepts_any: Any = self._get_required_shared(shared_context, "text_concepts")
            relationships_any: Any = self._get_required_shared(shared_context, "text_relationships")
            inventory_any: Any = shared_context.get("content_inventory_md")

            concepts_data: "WebContentConceptsList" = (
                cast("WebContentConceptsList", concepts_any)
                if isinstance(concepts_any, list) and all(isinstance(i, dict) for i in concepts_any)
                else []
            )
            relationships_data: "WebContentRelationshipsDict" = (
                cast("WebContentRelationshipsDict", relationships_any) if isinstance(relationships_any, dict) else {}
            )
            inventory_content: Optional[str] = str(inventory_any) if isinstance(inventory_any, str) else None

            if not concepts_data:  # Allow proceeding even if concepts are empty, review might still be generic
                self._log_warning("No web concepts data found. Web review might be generic based on inventory only.")

            # Ensure target_language is correctly fetched and passed
            target_language_str: str = str(shared_context.get("language", "english"))

            prepared_inputs: WebReviewPreparedInputs = {
                "skip": False,
                "document_collection_name": str(self._get_required_shared(shared_context, "project_name")),
                "concepts_data": concepts_data,
                "relationships_data": relationships_data,
                "inventory_content": inventory_content,
                "target_language": target_language_str,  # Ensure this is passed
                "llm_config": self._get_required_shared(shared_context, "llm_config"),
                "cache_config": self._get_required_shared(shared_context, "cache_config"),
            }
            return prepared_inputs
        except ValueError as e_prep_val:
            self._log_error("Preparation for web review failed (missing/invalid data): %s", e_prep_val)
            return {"skip": True, "reason": f"Data preparation error: {e_prep_val!s}"}
        except KeyError as e_key:
            self._log_error("Preparation for web review failed (config structure error): %s", e_key)
            return {"skip": True, "reason": f"Config structure error: {e_key!s}"}

    def execution(self, prepared_inputs: WebReviewPreparedInputs) -> WebReviewExecutionResult:
        """Generate the web content review using an LLM.

        Args:
            prepared_inputs (WebReviewPreparedInputs): Data from `pre_execution`.

        Returns:
            WebReviewExecutionResult: Markdown content of the review, or None/error string.
        """
        if prepared_inputs.get("skip", True):
            reason_str: str = str(prepared_inputs.get("reason", "N/A"))
            self._log_info("Skipping web content review execution. Reason: %s", reason_str)
            return None

        collection_name: str = prepared_inputs["document_collection_name"]
        target_lang: str = prepared_inputs["target_language"]  # Get target_language from prepared_inputs
        self._log_info(
            "Generating web content review for '%s' in language '%s' using LLM...", collection_name, target_lang
        )

        concepts: "WebContentConceptsList" = prepared_inputs["concepts_data"]
        relationships: "WebContentRelationshipsDict" = prepared_inputs["relationships_data"]
        inventory: Optional[str] = prepared_inputs["inventory_content"]
        llm_cfg_val: Any = prepared_inputs["llm_config"]
        cache_cfg_val: Any = prepared_inputs["cache_config"]
        llm_cfg: "LlmConfigDict" = cast("LlmConfigDict", llm_cfg_val)  # type: ignore[redundant-cast]
        cache_cfg: "CacheConfigDict" = cast("CacheConfigDict", cache_cfg_val)  # type: ignore[redundant-cast]

        prompt: str = WebReviewPrompts.format_generate_web_review_prompt(
            document_collection_name=collection_name,
            concepts_data=concepts,
            relationships_data=relationships,
            inventory_content=inventory,
            target_language=target_lang,  # Pass to prompt formatter
        )

        try:
            response_text: str = call_llm(prompt, llm_cfg, cache_cfg)
            validated_yaml_data: dict[str, Any] = validate_yaml_dict(response_text, WEB_REVIEW_SCHEMA)
            markdown_content: str = self._format_review_yaml_to_markdown(validated_yaml_data, collection_name)
            self._log_info("Successfully generated web content review.")
            return markdown_content
        except LlmApiError:
            # Log specifics in the LlmApiError itself, re-raise for node's retry.
            self._log_error(
                "LLM call failed during web review generation. This error will be re-raised for retry/fallback."
            )
            raise
        except ValidationFailure as e_val:
            self._log_error("YAML validation failed for web review: %s", e_val)
            return f"{ERROR_REVIEW_PREFIX} AI-generated review validation failed: {e_val!s}"
        except Exception as e_proc:  # Catch other unexpected errors during processing  # noqa: BLE001
            self._log_error("Unexpected error processing web review: %s", e_proc, exc_info=True)
            return f"{ERROR_REVIEW_PREFIX} Unexpected error generating review: {e_proc!s}"

    def execution_fallback(self, prepared_inputs: WebReviewPreparedInputs, exc: Exception) -> WebReviewExecutionResult:
        """Handle fallback if all execution attempts for web review fail.

        Args:
            prepared_inputs (WebReviewPreparedInputs): Data from `pre_execution`.
            exc (Exception): The exception from the last execution attempt.

        Returns:
            WebReviewExecutionResult: A Markdown string indicating the failure.
        """
        collection_name: str = prepared_inputs.get("document_collection_name", "Unknown Web Content")
        self._log_error(
            "All attempts to generate web review for '%s' failed. Last error: %s", collection_name, exc, exc_info=True
        )
        return (
            f"# Web Content Review: {collection_name}\n\n"
            f"> {ERROR_REVIEW_PREFIX} Could not be created after multiple attempts. Error: {exc!s}"
        )

    def post_execution(
        self,
        shared_context: SLSharedContext,
        prepared_inputs: WebReviewPreparedInputs,
        execution_outputs: WebReviewExecutionResult,
    ) -> None:
        """Store the generated web content review in shared_context.

        Args:
            shared_context (SLSharedContext): The shared context dictionary.
            prepared_inputs (WebReviewPreparedInputs): Data from `pre_execution`.
            execution_outputs (WebReviewExecutionResult): Markdown content of the review.
        """
        if prepared_inputs.get("skip", True):
            shared_context["web_content_review_md"] = None
            self._log_info("Web content review was skipped, 'web_content_review_md' set to None.")
            return

        shared_context["web_content_review_md"] = execution_outputs
        if execution_outputs and execution_outputs.strip() and not execution_outputs.startswith(ERROR_REVIEW_PREFIX):
            snippet: str = execution_outputs[:MAX_REVIEW_SNIPPET_LEN_LOG].replace("\n", " ")
            if len(execution_outputs) > MAX_REVIEW_SNIPPET_LEN_LOG:
                snippet += "..."
            self._log_info(
                "Stored web content review in shared_context['web_content_review_md'] (snippet: '%s').", snippet
            )
        else:
            self._log_warning("Web content review from execution was None, empty, or an error. Stored as is.")


# End of src/FL02_web_crawling/nodes/n07_generate_web_review.py
